count:0_repeat:0_time:2021-07-07 07:07:23
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5171bad6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 count:0_repeat:0_time:2021-07-07 07:17:41
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb56b3b56a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7644508670520231, max_test_f1: 0.7526005968079895
count:0_repeat:1_time:2021-07-07 07:31:19
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb56b3b56a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7543352601156069, max_test_f1: 0.7431393363772857
count:0_repeat:2_time:2021-07-07 07:46:09
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb56b3b56a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7586705202312138, max_test_f1: 0.7481549069544452
max_test_acc_avg: 0.7591522157996146, max_test_f1_avg: 0.7479649467132402

count:1_repeat:0_time:2021-07-07 08:01:08
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0356e656a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7774566473988439, max_test_f1: 0.7674721064376238
count:1_repeat:1_time:2021-07-07 08:14:33
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0356e656a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7456647398843931, max_test_f1: 0.7313634363276478
count:1_repeat:2_time:2021-07-07 08:28:59
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0356e656a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7615606936416185, max_test_f1: 0.7519321178763904
max_test_acc_avg: 0.7615606936416185, max_test_f1_avg: 0.750255886880554

count:2_repeat:0_time:2021-07-07 08:42:22
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa6081d76a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 2 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7601156069364162, max_test_f1: 0.7492897140417426
count:2_repeat:1_time:2021-07-07 08:55:34
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa6081d76a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 2 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.740137662628307
count:2_repeat:2_time:2021-07-07 09:07:04
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa6081d76a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 2 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7514450867052023, max_test_f1: 0.7406860945344421
max_test_acc_avg: 0.7567437379576107, max_test_f1_avg: 0.7433711570681639

count:3_repeat:0_time:2021-07-07 09:18:57
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f542c3966a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 3 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.773121387283237, max_test_f1: 0.7621062843260513
count:3_repeat:1_time:2021-07-07 09:31:48
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f542c3966a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 3 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7658959537572254, max_test_f1: 0.7539290950215842
count:3_repeat:2_time:2021-07-07 09:46:12
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f542c3966a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 3 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7512779122948613
max_test_acc_avg: 0.7673410404624277, max_test_f1_avg: 0.7557710972141657

count:4_repeat:0_time:2021-07-07 09:59:25
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5beba436a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 4 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7702312138728323, max_test_f1: 0.7619589842891931
count:4_repeat:1_time:2021-07-07 10:12:39
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5beba436a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 4 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7515518112932439
count:4_repeat:2_time:2021-07-07 10:24:27
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5beba436a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 4 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7601156069364162, max_test_f1: 0.747672370557976
max_test_acc_avg: 0.7644508670520231, max_test_f1_avg: 0.7537277220468043

count:5_repeat:0_time:2021-07-07 10:36:20
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efccd5b96a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 5 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7630057803468208, max_test_f1: 0.7531957262104311
count:5_repeat:1_time:2021-07-07 10:52:32
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efccd5b96a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 5 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7673410404624278, max_test_f1: 0.7543103448275863
count:5_repeat:2_time:2021-07-07 11:04:14
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efccd5b96a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 5 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7615606936416185, max_test_f1: 0.7518540265021016
max_test_acc_avg: 0.7639691714836223, max_test_f1_avg: 0.753120032513373

count:6_repeat:0_time:2021-07-07 11:16:17
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f47e319a6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 6 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7702312138728323, max_test_f1: 0.75694508733022
count:6_repeat:1_time:2021-07-07 11:27:54
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f47e319a6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 6 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7485549132947977, max_test_f1: 0.7425422493838765
count:6_repeat:2_time:2021-07-07 11:39:10
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f47e319a6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 6 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7545864661654135
max_test_acc_avg: 0.7605973025048169, max_test_f1_avg: 0.75135793429317

count:7_repeat:0_time:2021-07-07 11:53:57
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7febc4f356a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 7 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7658959537572254, max_test_f1: 0.7513404963261697
count:7_repeat:1_time:2021-07-07 12:07:13
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7febc4f356a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 7 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7499622934951393
count:7_repeat:2_time:2021-07-07 12:19:53
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7febc4f356a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 7 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7658959537572254, max_test_f1: 0.7557779563624125
max_test_acc_avg: 0.764932562620424, max_test_f1_avg: 0.7523602487279072

count:8_repeat:0_time:2021-07-07 12:31:44
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efdd71c36a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 8 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7615606936416185, max_test_f1: 0.7514713712777353
count:8_repeat:1_time:2021-07-07 12:45:03
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efdd71c36a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 8 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7507113061531632
count:8_repeat:2_time:2021-07-07 12:58:02
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efdd71c36a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 8 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7716763005780347, max_test_f1: 0.7602434077079109
max_test_acc_avg: 0.7654142581888247, max_test_f1_avg: 0.7541420283796031

count:9_repeat:0_time:2021-07-07 13:09:46
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fcfa76e46a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 9 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.773121387283237, max_test_f1: 0.7587961518710572
count:9_repeat:1_time:2021-07-07 13:22:55
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fcfa76e46a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 9 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7601156069364162, max_test_f1: 0.7438896458312806
count:9_repeat:2_time:2021-07-07 13:34:16
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fcfa76e46a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 9 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7601156069364162, max_test_f1: 0.7469754952793218
max_test_acc_avg: 0.7644508670520231, max_test_f1_avg: 0.7498870976605532

count:10_repeat:0_time:2021-07-07 13:47:24
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff6981196a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 10 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7630057803468208, max_test_f1: 0.7525034091770196
count:10_repeat:1_time:2021-07-07 14:00:15
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff6981196a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 10 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7644508670520231, max_test_f1: 0.7505233420124108
count:10_repeat:2_time:2021-07-07 14:13:03
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff6981196a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 10 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7535982724969893
max_test_acc_avg: 0.7634874759152215, max_test_f1_avg: 0.7522083412288065

count:11_repeat:0_time:2021-07-07 14:24:39
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3becb556a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 11 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7760115606936416, max_test_f1: 0.7656554158072275
count:11_repeat:1_time:2021-07-07 14:44:00
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3becb556a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 11 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.74664232393937
count:11_repeat:2_time:2021-07-07 14:57:24
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3becb556a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 11 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7586705202312138, max_test_f1: 0.7479502316048249
max_test_acc_avg: 0.7644508670520231, max_test_f1_avg: 0.7534159904504741

count:12_repeat:0_time:2021-07-07 15:10:31
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdb01c9f6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 12 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7658959537572254, max_test_f1: 0.7572910145489901
count:12_repeat:1_time:2021-07-07 15:23:50
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdb01c9f6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 12 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7511448894672982
count:12_repeat:2_time:2021-07-07 15:36:55
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdb01c9f6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 12 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7494449983383183
max_test_acc_avg: 0.7639691714836223, max_test_f1_avg: 0.7526269674515356

count:13_repeat:0_time:2021-07-07 15:48:38
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff22d24d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 13 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7673410404624278, max_test_f1: 0.7540412362979586
count:13_repeat:1_time:2021-07-07 16:01:40
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff22d24d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 13 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7673410404624278, max_test_f1: 0.756473965598298
count:13_repeat:2_time:2021-07-07 16:14:37
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff22d24d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 13 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7644508670520231, max_test_f1: 0.7544157754602119
max_test_acc_avg: 0.7663776493256261, max_test_f1_avg: 0.7549769924521561

count:14_repeat:0_time:2021-07-07 16:26:28
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f92a367b6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 14 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7673410404624278, max_test_f1: 0.7594282611002109
count:14_repeat:1_time:2021-07-07 16:39:44
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f92a367b6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 14 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7673410404624278, max_test_f1: 0.7542229691119254
count:14_repeat:2_time:2021-07-07 16:52:42
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f92a367b6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 14 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.773121387283237, max_test_f1: 0.7616599918494448
max_test_acc_avg: 0.7692678227360309, max_test_f1_avg: 0.758437074020527

count:15_repeat:0_time:2021-07-07 17:08:09
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0f25f0a6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 15 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7572254335260116, max_test_f1: 0.7464106688851481
count:15_repeat:1_time:2021-07-07 17:20:52
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0f25f0a6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 15 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7514450867052023, max_test_f1: 0.7386099544070497
count:15_repeat:2_time:2021-07-07 17:33:50
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0f25f0a6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 15 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7517080185325707
max_test_acc_avg: 0.7572254335260116, max_test_f1_avg: 0.7455762139415896

count:16_repeat:0_time:2021-07-07 17:45:17
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa93ec646a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 16 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7601156069364162, max_test_f1: 0.7469751619187549
count:16_repeat:1_time:2021-07-07 17:58:21
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa93ec646a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 16 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7543352601156069, max_test_f1: 0.7387630833250167
count:16_repeat:2_time:2021-07-07 18:11:18
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa93ec646a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 16 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7494968382077656
max_test_acc_avg: 0.7591522157996146, max_test_f1_avg: 0.7450783611505124

count:17_repeat:0_time:2021-07-07 18:23:29
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6220c926a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 17 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7601156069364162, max_test_f1: 0.7457776652236799
count:17_repeat:1_time:2021-07-07 18:36:39
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6220c926a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 17 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7557803468208093, max_test_f1: 0.7451567698108773
count:17_repeat:2_time:2021-07-07 18:52:29
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6220c926a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 17 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7673410404624278, max_test_f1: 0.7582318774170034
max_test_acc_avg: 0.7610789980732178, max_test_f1_avg: 0.7497221041505201

count:18_repeat:0_time:2021-07-07 19:04:05
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a045616a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 18 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.773121387283237, max_test_f1: 0.7618315989999357
count:18_repeat:1_time:2021-07-07 19:17:10
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a045616a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 18 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7471098265895953, max_test_f1: 0.7364227413767859
count:18_repeat:2_time:2021-07-07 19:28:46
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a045616a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 18 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7615606936416185, max_test_f1: 0.7454475235363761
max_test_acc_avg: 0.7605973025048169, max_test_f1_avg: 0.7479006213043659

count:19_repeat:0_time:2021-07-07 19:48:06
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f73233ad6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 19 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7687861271676301, max_test_f1: 0.7517750968837925
count:19_repeat:1_time:2021-07-07 20:01:09
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f73233ad6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 19 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7486790508369049
count:19_repeat:2_time:2021-07-07 20:12:45
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f73233ad6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 19 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7644508670520231, max_test_f1: 0.7524486623976773
max_test_acc_avg: 0.7654142581888247, max_test_f1_avg: 0.7509676033727916

count:20_repeat:0_time:2021-07-07 20:24:28
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4e5e6696a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 20 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7601156069364162, max_test_f1: 0.7519540483408739
count:20_repeat:1_time:2021-07-07 20:37:18
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4e5e6696a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 20 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.7482601221214952
count:20_repeat:2_time:2021-07-07 20:51:59
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4e5e6696a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 20 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7615606936416185, max_test_f1: 0.7500448095642533
max_test_acc_avg: 0.7601156069364162, max_test_f1_avg: 0.7500863266755408

count:21_repeat:0_time:2021-07-07 21:05:15
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0cb5f696a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 21 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7687861271676301, max_test_f1: 0.7598520324979816
count:21_repeat:1_time:2021-07-07 21:16:44
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0cb5f696a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 21 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7644508670520231, max_test_f1: 0.7590734699201932
count:21_repeat:2_time:2021-07-07 21:29:41
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0cb5f696a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 21 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7572254335260116, max_test_f1: 0.745966374557849
max_test_acc_avg: 0.7634874759152216, max_test_f1_avg: 0.754963958992008

count:22_repeat:0_time:2021-07-07 21:41:21
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3c622e16a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 22 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7673410404624278, max_test_f1: 0.7563122423042552
count:22_repeat:1_time:2021-07-07 21:54:23
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3c622e16a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 22 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7572254335260116, max_test_f1: 0.7434559439403311
count:22_repeat:2_time:2021-07-07 22:05:39
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3c622e16a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 22 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7507072230768705
max_test_acc_avg: 0.7625240847784199, max_test_f1_avg: 0.750158469773819

count:23_repeat:0_time:2021-07-07 22:17:26
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f01b42c46a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 23 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7687861271676301, max_test_f1: 0.7528418133958726
count:23_repeat:1_time:2021-07-07 22:29:03
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f01b42c46a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 23 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7745664739884393, max_test_f1: 0.7603786024785723
count:23_repeat:2_time:2021-07-07 22:40:20
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f01b42c46a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 23 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7572254335260116, max_test_f1: 0.7451925068917101
max_test_acc_avg: 0.766859344894027, max_test_f1_avg: 0.7528043075887183

count:24_repeat:0_time:2021-07-07 23:00:23
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f31f96616a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 24 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7745664739884393, max_test_f1: 0.763995584086894
count:24_repeat:1_time:2021-07-07 23:13:28
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f31f96616a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 24 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7543352601156069, max_test_f1: 0.7415634603712317
count:24_repeat:2_time:2021-07-07 23:26:36
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f31f96616a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 24 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7745664739884393, max_test_f1: 0.7603721849230832
max_test_acc_avg: 0.7678227360308285, max_test_f1_avg: 0.7553104097937363

count:25_repeat:0_time:2021-07-07 23:38:37
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f80396a26a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 25 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7615606936416185, max_test_f1: 0.7512089664085052
count:25_repeat:1_time:2021-07-07 23:51:54
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f80396a26a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 25 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7702312138728323, max_test_f1: 0.7580383426298906
count:25_repeat:2_time:2021-07-08 00:04:55
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f80396a26a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 25 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7658959537572254, max_test_f1: 0.7511524832643772
max_test_acc_avg: 0.7658959537572253, max_test_f1_avg: 0.7534665974342577

count:26_repeat:0_time:2021-07-08 00:19:53
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f8afe56e6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 26 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7586705202312138, max_test_f1: 0.7443049921441368
count:26_repeat:1_time:2021-07-08 00:32:41
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f8afe56e6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 26 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.7463270132745125
count:26_repeat:2_time:2021-07-08 00:45:52
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f8afe56e6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 26 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.773121387283237, max_test_f1: 0.7609745634802162
max_test_acc_avg: 0.7634874759152215, max_test_f1_avg: 0.7505355229662886

count:27_repeat:0_time:2021-07-08 00:57:57
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc7c8bee6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 27 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7586705202312138, max_test_f1: 0.7462170003454043
count:27_repeat:1_time:2021-07-08 01:08:30
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc7c8bee6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 27 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.7479752344798184
count:27_repeat:2_time:2021-07-08 01:20:30
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc7c8bee6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 27 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.773121387283237, max_test_f1: 0.7555876993606191
max_test_acc_avg: 0.7634874759152215, max_test_f1_avg: 0.7499266447286139

count:28_repeat:0_time:2021-07-08 01:32:52
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f88a09486a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 28 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7630057803468208, max_test_f1: 0.7476841370389216
count:28_repeat:1_time:2021-07-08 01:44:55
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f88a09486a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 28 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7601156069364162, max_test_f1: 0.7467040994996031
count:28_repeat:2_time:2021-07-08 01:54:54
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f88a09486a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 28 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.773121387283237, max_test_f1: 0.7635851376367756
max_test_acc_avg: 0.7654142581888247, max_test_f1_avg: 0.7526577913917668

count:29_repeat:0_time:2021-07-08 02:09:58
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3456cf16a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 29 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7586705202312138, max_test_f1: 0.7423796457672616
count:29_repeat:1_time:2021-07-08 02:20:42
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3456cf16a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 29 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.7440849902601685
count:29_repeat:2_time:2021-07-08 02:40:51
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3456cf16a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 29 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7543352601156069, max_test_f1: 0.7420964739894617
max_test_acc_avg: 0.7572254335260116, max_test_f1_avg: 0.7428537033389638

count:30_repeat:0_time:2021-07-08 02:51:43
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f52a28aa6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 30 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7557803468208093, max_test_f1: 0.7443414886781669
count:30_repeat:1_time:2021-07-08 03:05:08
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f52a28aa6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 30 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7658959537572254, max_test_f1: 0.7562235911805137
count:30_repeat:2_time:2021-07-08 03:15:46
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f52a28aa6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 30 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7673410404624278, max_test_f1: 0.7572551917806708
max_test_acc_avg: 0.7630057803468208, max_test_f1_avg: 0.7526067572131171

count:31_repeat:0_time:2021-07-08 03:26:40
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb3b1e7b6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 31 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7644508670520231, max_test_f1: 0.7542600330389281
count:31_repeat:1_time:2021-07-08 03:43:57
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb3b1e7b6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 31 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7702312138728323, max_test_f1: 0.7590138674884437
count:31_repeat:2_time:2021-07-08 03:55:47
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb3b1e7b6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 31 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7615606936416185, max_test_f1: 0.7501728303121364
max_test_acc_avg: 0.7654142581888247, max_test_f1_avg: 0.7544822436131694

count:32_repeat:0_time:2021-07-08 04:08:38
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbda6a1d6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 32 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7543352601156069, max_test_f1: 0.7399557337136954
count:32_repeat:1_time:2021-07-08 04:18:47
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbda6a1d6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 32 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7524652960563619
count:32_repeat:2_time:2021-07-08 04:32:56
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbda6a1d6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 32 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7526567141376149
max_test_acc_avg: 0.7601156069364161, max_test_f1_avg: 0.748359247969224

count:33_repeat:0_time:2021-07-08 04:44:47
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f96fb7576a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 33 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7774566473988439, max_test_f1: 0.7535525858736403
count:33_repeat:1_time:2021-07-08 04:55:01
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f96fb7576a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 33 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7687861271676301, max_test_f1: 0.7627003318161476
count:33_repeat:2_time:2021-07-08 05:05:27
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f96fb7576a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 33 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7716763005780347, max_test_f1: 0.7549351426939935
max_test_acc_avg: 0.7726396917148363, max_test_f1_avg: 0.7570626867945939

count:34_repeat:0_time:2021-07-08 05:15:58
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9348d5e6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 34 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7557803468208093, max_test_f1: 0.7415802024929836
count:34_repeat:1_time:2021-07-08 05:28:43
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9348d5e6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 34 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7615606936416185, max_test_f1: 0.7474677542813404
count:34_repeat:2_time:2021-07-08 05:38:55
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9348d5e6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 34 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7687861271676301, max_test_f1: 0.7546108272953512
max_test_acc_avg: 0.7620423892100193, max_test_f1_avg: 0.7478862613565584

count:35_repeat:0_time:2021-07-08 05:50:45
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a6a2816a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 35 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7572254335260116, max_test_f1: 0.7462368827285358
count:35_repeat:1_time:2021-07-08 06:01:02
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a6a2816a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 35 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7572254335260116, max_test_f1: 0.7472426182833424
count:35_repeat:2_time:2021-07-08 06:12:25
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a6a2816a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 35 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7658959537572254, max_test_f1: 0.7559317951474814
max_test_acc_avg: 0.7601156069364162, max_test_f1_avg: 0.7498037653864532

count:36_repeat:0_time:2021-07-08 06:24:07
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5d5db6f6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 36 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7630057803468208, max_test_f1: 0.7532944361856829
count:36_repeat:1_time:2021-07-08 06:35:48
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5d5db6f6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 36 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7658959537572254, max_test_f1: 0.7556110390999584
count:36_repeat:2_time:2021-07-08 06:55:22
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5d5db6f6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 36 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7745664739884393, max_test_f1: 0.757948927429991
max_test_acc_avg: 0.7678227360308285, max_test_f1_avg: 0.7556181342385441

count:37_repeat:0_time:2021-07-08 07:07:21
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f83f42bc6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 37 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7687861271676301, max_test_f1: 0.7534013378035294
count:37_repeat:1_time:2021-07-08 07:20:47
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f83f42bc6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 37 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7687861271676301, max_test_f1: 0.7538389489299081
count:37_repeat:2_time:2021-07-08 07:31:03
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f83f42bc6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 37 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7673410404624278, max_test_f1: 0.7566800113395148
max_test_acc_avg: 0.7683044315992293, max_test_f1_avg: 0.7546400993576508

count:38_repeat:0_time:2021-07-08 07:42:44
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5a97ae86a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 38 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7630057803468208, max_test_f1: 0.7483549777892599
count:38_repeat:1_time:2021-07-08 07:53:19
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5a97ae86a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 38 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7572254335260116, max_test_f1: 0.7444583831816395
count:38_repeat:2_time:2021-07-08 08:05:18
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5a97ae86a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 38 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7658959537572254, max_test_f1: 0.7521303137122347
max_test_acc_avg: 0.7620423892100193, max_test_f1_avg: 0.7483145582277113

count:39_repeat:0_time:2021-07-08 08:24:24
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f58c45686a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 39 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7601156069364162, max_test_f1: 0.7497858359116648
count:39_repeat:1_time:2021-07-08 08:36:31
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f58c45686a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 39 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7543352601156069, max_test_f1: 0.7394046533885125
count:39_repeat:2_time:2021-07-08 08:48:04
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f58c45686a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 39 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7803468208092486, max_test_f1: 0.7686918445539135
max_test_acc_avg: 0.764932562620424, max_test_f1_avg: 0.7526274446180302

count:40_repeat:0_time:2021-07-08 09:00:07
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7a8b7026a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 40 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.773121387283237, max_test_f1: 0.7551028593112781
count:40_repeat:1_time:2021-07-08 09:12:04
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7a8b7026a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 40 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7615606936416185, max_test_f1: 0.7499162297344591
count:40_repeat:2_time:2021-07-08 09:25:14
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7a8b7026a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 40 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7687861271676301, max_test_f1: 0.7558910282487532
max_test_acc_avg: 0.7678227360308285, max_test_f1_avg: 0.7536367057648302

count:41_repeat:0_time:2021-07-08 09:37:35
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7b9ad716a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 41 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7716763005780347, max_test_f1: 0.7625325017162758
count:41_repeat:1_time:2021-07-08 09:49:28
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7b9ad716a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 41 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7522525337793127
count:41_repeat:2_time:2021-07-08 10:01:19
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7b9ad716a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 41 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.773121387283237, max_test_f1: 0.760166779642447
max_test_acc_avg: 0.7692678227360309, max_test_f1_avg: 0.7583172717126785

count:42_repeat:0_time:2021-07-08 10:12:18
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f59ed25b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 42 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7673410404624278, max_test_f1: 0.7571757195757646
count:42_repeat:1_time:2021-07-08 10:24:07
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f59ed25b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 42 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7469979296066253
count:42_repeat:2_time:2021-07-08 10:35:48
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f59ed25b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 42 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7687861271676301, max_test_f1: 0.7558968536893867
max_test_acc_avg: 0.7663776493256261, max_test_f1_avg: 0.7533568342905922

count:43_repeat:0_time:2021-07-08 10:47:53
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb44f4ec6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 43 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7658959537572254, max_test_f1: 0.7520471817418951
count:43_repeat:1_time:2021-07-08 11:00:02
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb44f4ec6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 43 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7615606936416185, max_test_f1: 0.7473749840414007
count:43_repeat:2_time:2021-07-08 11:13:09
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb44f4ec6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 43 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7803468208092486, max_test_f1: 0.7687277980230877
max_test_acc_avg: 0.7692678227360309, max_test_f1_avg: 0.7560499879354611

count:44_repeat:0_time:2021-07-08 11:25:30
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb0806276a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 44 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7716763005780347, max_test_f1: 0.7580289335680166
count:44_repeat:1_time:2021-07-08 11:36:11
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb0806276a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 44 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7572254335260116, max_test_f1: 0.7421614230303396
count:44_repeat:2_time:2021-07-08 11:46:40
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb0806276a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 44 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7702312138728323, max_test_f1: 0.7551193050356129
max_test_acc_avg: 0.7663776493256261, max_test_f1_avg: 0.751769887211323

count:45_repeat:0_time:2021-07-08 11:58:17
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc92058f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 45 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7644508670520231, max_test_f1: 0.7556230027951005
count:45_repeat:1_time:2021-07-08 12:11:51
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc92058f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 45 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7658959537572254, max_test_f1: 0.755208441598391
count:45_repeat:2_time:2021-07-08 12:23:37
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc92058f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 45 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7702312138728323, max_test_f1: 0.7588364786245755
max_test_acc_avg: 0.766859344894027, max_test_f1_avg: 0.7565559743393556

count:46_repeat:0_time:2021-07-08 12:36:15
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6b2e3126a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 46 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7745664739884393, max_test_f1: 0.7624359566799311
count:46_repeat:1_time:2021-07-08 12:52:27
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6b2e3126a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 46 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7716763005780347, max_test_f1: 0.7577470046859626
count:46_repeat:2_time:2021-07-08 13:03:14
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6b2e3126a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 46 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7716763005780347, max_test_f1: 0.760071014077431
max_test_acc_avg: 0.7726396917148363, max_test_f1_avg: 0.7600846584811083

count:47_repeat:0_time:2021-07-08 13:14:06
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbdd41e56a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 47 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7673410404624278, max_test_f1: 0.7583459419174141
count:47_repeat:1_time:2021-07-08 13:25:59
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbdd41e56a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 47 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7557970658599485
count:47_repeat:2_time:2021-07-08 13:36:24
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbdd41e56a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 47 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.773121387283237, max_test_f1: 0.7616942425107102
max_test_acc_avg: 0.7678227360308285, max_test_f1_avg: 0.7586124167626909

count:48_repeat:0_time:2021-07-08 13:50:08
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f13eb34c6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 48 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7716763005780347, max_test_f1: 0.75700176827391
count:48_repeat:1_time:2021-07-08 14:07:32
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f13eb34c6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 48 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7745664739884393, max_test_f1: 0.7622640897272106
count:48_repeat:2_time:2021-07-08 14:33:12
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f13eb34c6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 48 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.773121387283237, max_test_f1: 0.7601624819440542
max_test_acc_avg: 0.7731213872832369, max_test_f1_avg: 0.7598094466483917

count:49_repeat:0_time:2021-07-08 14:44:36
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa2f57b16a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 49 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7630057803468208, max_test_f1: 0.7495626385306781
count:49_repeat:1_time:2021-07-08 14:56:54
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa2f57b16a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 49 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7644508670520231, max_test_f1: 0.755864297214985
count:49_repeat:2_time:2021-07-08 15:09:05
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa2f57b16a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 49 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7760115606936416, max_test_f1: 0.76432226827922
max_test_acc_avg: 0.7678227360308285, max_test_f1_avg: 0.7565830680082944

count:50_repeat:0_time:2021-07-08 15:20:17
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa3ce2616a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 50 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7716763005780347, max_test_f1: 0.7586066869358299
count:50_repeat:1_time:2021-07-08 15:32:16
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa3ce2616a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 50 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7601156069364162, max_test_f1: 0.750306947685233
count:50_repeat:2_time:2021-07-08 15:42:38
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa3ce2616a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 50 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7687861271676301, max_test_f1: 0.7550400121463765
max_test_acc_avg: 0.766859344894027, max_test_f1_avg: 0.7546512155891465

count:51_repeat:0_time:2021-07-08 15:53:23
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f99e864f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 51 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7687861271676301, max_test_f1: 0.7566328881523875
count:51_repeat:1_time:2021-07-08 16:05:43
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f99e864f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 51 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7702312138728323, max_test_f1: 0.7568561818066287
count:51_repeat:2_time:2021-07-08 16:20:26
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f99e864f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 51 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7803468208092486, max_test_f1: 0.7654135112479293
max_test_acc_avg: 0.7731213872832369, max_test_f1_avg: 0.7596341937356486

count:52_repeat:0_time:2021-07-08 16:31:15
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc064cf66a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 52 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7716763005780347, max_test_f1: 0.7575374257468827
count:52_repeat:1_time:2021-07-08 16:41:30
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc064cf66a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 52 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7509094462461142
count:52_repeat:2_time:2021-07-08 16:51:49
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc064cf66a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 52 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7431374779979727
max_test_acc_avg: 0.7658959537572253, max_test_f1_avg: 0.7505281166636566

count:53_repeat:0_time:2021-07-08 17:02:37
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff5b74cd6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 53 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7644508670520231, max_test_f1: 0.7466502507224222
count:53_repeat:1_time:2021-07-08 17:14:20
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff5b74cd6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 53 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7630057803468208, max_test_f1: 0.7510122414668744
count:53_repeat:2_time:2021-07-08 17:30:06
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff5b74cd6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 53 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7774566473988439, max_test_f1: 0.7676080498137933
max_test_acc_avg: 0.7683044315992292, max_test_f1_avg: 0.7550901806676965

count:54_repeat:0_time:2021-07-08 17:42:23
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5a667af6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 54 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7702312138728323, max_test_f1: 0.75456656842199
count:54_repeat:1_time:2021-07-08 17:52:11
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5a667af6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 54 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7702312138728323, max_test_f1: 0.7569310535247494
count:54_repeat:2_time:2021-07-08 18:03:16
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5a667af6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 54 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7774566473988439, max_test_f1: 0.7663934770121678
max_test_acc_avg: 0.7726396917148363, max_test_f1_avg: 0.7592970329863024

count:55_repeat:0_time:2021-07-08 18:13:12
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6c27f816a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 55 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7644508670520231, max_test_f1: 0.7541809044421859
count:55_repeat:1_time:2021-07-08 18:24:43
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6c27f816a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 55 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7673410404624278, max_test_f1: 0.755622820684243
count:55_repeat:2_time:2021-07-08 18:34:54
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6c27f816a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 55 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7702312138728323, max_test_f1: 0.7571388153847866
max_test_acc_avg: 0.7673410404624277, max_test_f1_avg: 0.7556475135037385

count:56_repeat:0_time:2021-07-08 18:46:20
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdeb199c6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 56 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7687861271676301, max_test_f1: 0.7552132768904798
count:56_repeat:1_time:2021-07-08 18:57:23
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdeb199c6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 56 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7658959537572254, max_test_f1: 0.7570884146105725
count:56_repeat:2_time:2021-07-08 19:07:14
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdeb199c6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 56 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7644508670520231, max_test_f1: 0.7530828883803712
max_test_acc_avg: 0.7663776493256261, max_test_f1_avg: 0.7551281932938078

count:57_repeat:0_time:2021-07-08 19:23:32
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f16ab6ec6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 57 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7760115606936416, max_test_f1: 0.7639581458252126
count:57_repeat:1_time:2021-07-08 19:34:25
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f16ab6ec6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 57 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7615606936416185, max_test_f1: 0.7535247626990746
count:57_repeat:2_time:2021-07-08 19:44:09
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f16ab6ec6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 57 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7630057803468208, max_test_f1: 0.7478971493797122
max_test_acc_avg: 0.766859344894027, max_test_f1_avg: 0.7551266859679998

count:58_repeat:0_time:2021-07-08 19:56:08
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa9318486a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 58 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7644508670520231, max_test_f1: 0.7504949701209315
count:58_repeat:1_time:2021-07-08 20:06:08
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa9318486a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 58 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.7435255100474674
count:58_repeat:2_time:2021-07-08 20:17:01
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa9318486a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 58 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7601156069364162, max_test_f1: 0.7483600416568118
max_test_acc_avg: 0.7610789980732178, max_test_f1_avg: 0.7474601739417368

count:59_repeat:0_time:2021-07-08 20:28:06
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f781c1e26a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 59 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7716763005780347, max_test_f1: 0.7587470503391791
count:59_repeat:1_time:2021-07-08 20:41:31
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f781c1e26a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 59 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7673410404624278, max_test_f1: 0.7547754824527223
count:59_repeat:2_time:2021-07-08 21:00:03
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f781c1e26a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 59 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7644508670520231, max_test_f1: 0.7476063809720159
max_test_acc_avg: 0.7678227360308285, max_test_f1_avg: 0.7537096379213057

count:60_repeat:0_time:2021-07-08 21:08:43
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f638468f6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 60 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7572254335260116, max_test_f1: 0.7423051124065584
count:60_repeat:1_time:2021-07-08 21:19:54
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f638468f6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 60 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7543352601156069, max_test_f1: 0.7416107809328149
count:60_repeat:2_time:2021-07-08 21:29:32
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f638468f6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 60 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7658959537572254, max_test_f1: 0.7583036813904543
max_test_acc_avg: 0.7591522157996146, max_test_f1_avg: 0.7474065249099425

count:61_repeat:0_time:2021-07-08 21:39:48
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdd6fb576a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 61 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7774566473988439, max_test_f1: 0.7657185730357532
count:61_repeat:1_time:2021-07-08 21:51:30
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdd6fb576a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 61 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7658959537572254, max_test_f1: 0.7563783650836621
count:61_repeat:2_time:2021-07-08 22:06:29
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdd6fb576a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 61 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7644508670520231, max_test_f1: 0.7501567904592941
max_test_acc_avg: 0.7692678227360309, max_test_f1_avg: 0.7574179095262364

count:62_repeat:0_time:2021-07-08 22:17:30
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f45b092d6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 62 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7658959537572254, max_test_f1: 0.7555411255411256
count:62_repeat:1_time:2021-07-08 22:28:29
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f45b092d6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 62 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7572254335260116, max_test_f1: 0.7423950004595166
count:62_repeat:2_time:2021-07-08 22:38:00
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f45b092d6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 62 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7673410404624278, max_test_f1: 0.7528440055725185
max_test_acc_avg: 0.7634874759152216, max_test_f1_avg: 0.7502600438577202

count:63_repeat:0_time:2021-07-08 22:48:56
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f65df39b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 63 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7774566473988439, max_test_f1: 0.7614510645911611
count:63_repeat:1_time:2021-07-08 22:59:50
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f65df39b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 63 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7615606936416185, max_test_f1: 0.7485951956540191
count:63_repeat:2_time:2021-07-08 23:15:50
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f65df39b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 63 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7745664739884393, max_test_f1: 0.7643982442506142
max_test_acc_avg: 0.7711946050096339, max_test_f1_avg: 0.7581481681652648

count:64_repeat:0_time:2021-07-08 23:34:42
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7bc69a56a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 64 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7673410404624278, max_test_f1: 0.7554152000209755
count:64_repeat:1_time:2021-07-08 23:44:35
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7bc69a56a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 64 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.7493137797072161
count:64_repeat:2_time:2021-07-08 23:54:28
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7bc69a56a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 64 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.773121387283237, max_test_f1: 0.7620955830908311
max_test_acc_avg: 0.7663776493256261, max_test_f1_avg: 0.7556081876063409

count:65_repeat:0_time:2021-07-09 00:07:36
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2de7d2c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 65 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7716763005780347, max_test_f1: 0.7605527390909762
count:65_repeat:1_time:2021-07-09 00:18:50
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2de7d2c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 65 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7687861271676301, max_test_f1: 0.7533848098695056
count:65_repeat:2_time:2021-07-09 00:28:19
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2de7d2c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 65 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7716763005780347, max_test_f1: 0.7558921328072391
max_test_acc_avg: 0.7707129094412332, max_test_f1_avg: 0.7566098939225737

count:66_repeat:0_time:2021-07-09 00:38:10
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd1fca406a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 66 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7745664739884393, max_test_f1: 0.7599833262130472
count:66_repeat:1_time:2021-07-09 00:51:34
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd1fca406a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 66 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7702312138728323, max_test_f1: 0.7605809332879877
count:66_repeat:2_time:2021-07-09 01:01:10
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd1fca406a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 66 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7687861271676301, max_test_f1: 0.7593843125073579
max_test_acc_avg: 0.7711946050096339, max_test_f1_avg: 0.7599828573361309

count:67_repeat:0_time:2021-07-09 01:12:37
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbe44d146a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 67 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7789017341040463, max_test_f1: 0.7658897962265779
count:67_repeat:1_time:2021-07-09 01:23:53
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbe44d146a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 67 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7586705202312138, max_test_f1: 0.7449495498932871
count:67_repeat:2_time:2021-07-09 01:36:08
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbe44d146a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 67 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.7673410404624278, max_test_f1: 0.751288449263737
max_test_acc_avg: 0.7683044315992293, max_test_f1_avg: 0.7540425984612007

count:68_repeat:0_time:2021-07-09 01:47:01
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbe8e4446a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 68 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.7687861271676301, max_test_f1: 0.7577583414318108
count:68_repeat:1_time:2021-07-09 01:57:50
 model_name: EnsembleDB dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbe8e4446a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 68 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 