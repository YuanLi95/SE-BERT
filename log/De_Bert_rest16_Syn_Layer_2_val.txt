time:2021-06-23 16:53:22
 model_name: De_Bert dataset: rest16 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001C80ABAC950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] 