time:2021-06-19 14:30:18
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000023B0CBBD950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 8 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 19:58:54
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001A30B32D950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:00:32
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001C309D2D950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:01:06
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x00000187106BC950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:01:45
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001B68A0ED950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 5 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:02:15
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000027A90E8D950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 5 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:04:05
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000024E0D9CD950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 5 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:04:49
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001190B23D950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 5 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:05:42
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001D7104CD950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 5 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:06:30
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000018E101CD950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 5 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] time:2021-06-19 20:07:06
 model_name: De_Bert dataset: twitter optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000021309B4D950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw Syn_Layer: 2 SRD: 3 lr_de: 0.5 DB_begin_layer: 5 DT_layer_number: 6 model_class: <class 'models.dependency_bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] 