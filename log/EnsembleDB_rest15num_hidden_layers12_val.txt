count:0_repeat:0_time:2021-07-06 13:35:24
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f29dde506a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 count:0_repeat:0_time:2021-07-06 13:39:19
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd5298076a8> learning_rate: 1.6e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8228782287822878, max_test_f1: 0.6763192130817718
count:0_repeat:1_time:2021-07-06 13:42:58
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd5298076a8> learning_rate: 1.6e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 count:0_repeat:0_time:2021-07-06 13:46:42
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f29b0d706a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6917462000706963
count:0_repeat:1_time:2021-07-06 13:50:04
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f29b0d706a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8413284132841329, max_test_f1: 0.6688565809804747
count:0_repeat:2_time:2021-07-06 13:53:06
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f29b0d706a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8339483394833949, max_test_f1: 0.6760783085194108
count:1_repeat:0_time:2021-07-06 13:56:30
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9357cb56a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8302583025830258, max_test_f1: 0.6808397059494496
count:1_repeat:1_time:2021-07-06 13:59:29
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9357cb56a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8284132841328413, max_test_f1: 0.6906248320172393
count:1_repeat:2_time:2021-07-06 14:02:57
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9357cb56a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 count:0_repeat:0_time:2021-07-06 14:06:12
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbfa018c6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8191881918819188, max_test_f1: 0.6775883786522084
count:0_repeat:0_time:2021-07-06 14:11:20
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f08373ed6a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8339483394833949, max_test_f1: 0.6668318893799029
count:0_repeat:1_time:2021-07-06 14:15:35
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f08373ed6a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8468634686346863, max_test_f1: 0.6937388651390907
count:0_repeat:2_time:2021-07-06 14:18:30
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f08373ed6a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 0 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8265682656826568, max_test_f1: 0.660481273289964
count:1_repeat:0_time:2021-07-06 14:21:55
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6d2073d6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8487084870848709, max_test_f1: 0.7126832019549405
count:1_repeat:1_time:2021-07-06 14:25:57
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6d2073d6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8357933579335793, max_test_f1: 0.6829398022008443
count:1_repeat:2_time:2021-07-06 14:29:51
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6d2073d6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 1 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8321033210332104, max_test_f1: 0.6953042434843523
count:2_repeat:0_time:2021-07-06 14:32:54
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f68ec70a6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 2 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6849406488693756
count:2_repeat:1_time:2021-07-06 14:36:20
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f68ec70a6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 2 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8302583025830258, max_test_f1: 0.6941409590212458
count:2_repeat:2_time:2021-07-06 14:39:37
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f68ec70a6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 2 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8339483394833949, max_test_f1: 0.6908576546855739
count:3_repeat:0_time:2021-07-06 14:44:19
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa9f12b06a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 3 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8394833948339483, max_test_f1: 0.6634662782187444
count:3_repeat:1_time:2021-07-06 14:46:52
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa9f12b06a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 3 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8321033210332104, max_test_f1: 0.6613325281803543
count:3_repeat:2_time:2021-07-06 14:50:05
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa9f12b06a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 3 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8228782287822878, max_test_f1: 0.6731911476568272
count:4_repeat:0_time:2021-07-06 14:54:05
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc7f7a2f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 4 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6812122360470747
count:4_repeat:1_time:2021-07-06 14:57:58
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc7f7a2f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 4 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8247232472324724, max_test_f1: 0.6600051875805671
count:4_repeat:2_time:2021-07-06 15:01:47
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc7f7a2f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 4 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8394833948339483, max_test_f1: 0.6843639931565039
count:5_repeat:0_time:2021-07-06 15:05:03
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efc8932c6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 5 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6656279198870383
count:5_repeat:1_time:2021-07-06 15:08:26
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efc8932c6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 5 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8284132841328413, max_test_f1: 0.6815340324236233
count:5_repeat:2_time:2021-07-06 15:12:00
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efc8932c6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 5 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8302583025830258, max_test_f1: 0.6568756654989892
count:6_repeat:0_time:2021-07-06 15:15:20
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3e132186a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 6 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6887491264849755
count:6_repeat:1_time:2021-07-06 15:18:59
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3e132186a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 6 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.7970479704797048, max_test_f1: 0.6378876111848247
count:6_repeat:2_time:2021-07-06 15:24:07
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3e132186a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 6 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8357933579335793, max_test_f1: 0.6919336791230369
count:7_repeat:0_time:2021-07-06 15:27:36
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7a99d1a6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 7 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8376383763837638, max_test_f1: 0.7133616480841264
count:7_repeat:1_time:2021-07-06 15:31:42
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7a99d1a6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 7 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8302583025830258, max_test_f1: 0.6826055584377949
count:7_repeat:2_time:2021-07-06 15:35:10
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7a99d1a6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 7 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8579335793357934, max_test_f1: 0.7438086448238733
count:8_repeat:0_time:2021-07-06 15:38:09
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0243e7d6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 8 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8394833948339483, max_test_f1: 0.6706337528013296
count:8_repeat:1_time:2021-07-06 15:40:56
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0243e7d6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 8 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8450184501845018, max_test_f1: 0.6892543859649122
count:8_repeat:2_time:2021-07-06 15:43:54
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f0243e7d6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 8 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8394833948339483, max_test_f1: 0.6837559694702552
count:9_repeat:0_time:2021-07-06 15:47:38
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f86803716a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 9 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6815313896761861
count:9_repeat:1_time:2021-07-06 15:50:40
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f86803716a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 9 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8394833948339483, max_test_f1: 0.6586534605504005
count:9_repeat:2_time:2021-07-06 15:53:17
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f86803716a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 9 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8357933579335793, max_test_f1: 0.6871323706355864
count:10_repeat:0_time:2021-07-06 15:57:44
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4cbbc1f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 10 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8284132841328413, max_test_f1: 0.6470877534577683
count:10_repeat:1_time:2021-07-06 16:00:33
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4cbbc1f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 10 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8339483394833949, max_test_f1: 0.6564522890002448
count:10_repeat:2_time:2021-07-06 16:02:59
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4cbbc1f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 10 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8247232472324724, max_test_f1: 0.6953297795689442
count:11_repeat:0_time:2021-07-06 16:06:38
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fad3447c6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 11 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8339483394833949, max_test_f1: 0.7005105321942143
count:11_repeat:1_time:2021-07-06 16:11:36
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fad3447c6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 11 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8284132841328413, max_test_f1: 0.6583833177557373
count:11_repeat:2_time:2021-07-06 16:14:29
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fad3447c6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 11 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8487084870848709, max_test_f1: 0.7025991925767481
count:12_repeat:0_time:2021-07-06 16:17:53
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f364b02c6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 12 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8394833948339483, max_test_f1: 0.701547614926946
count:12_repeat:1_time:2021-07-06 16:20:57
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f364b02c6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 12 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8339483394833949, max_test_f1: 0.669776535629433
count:12_repeat:2_time:2021-07-06 16:24:28
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f364b02c6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 12 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8302583025830258, max_test_f1: 0.7143671850679568
count:13_repeat:0_time:2021-07-06 16:28:17
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2e667256a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 13 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8394833948339483, max_test_f1: 0.7030591329233863
count:13_repeat:1_time:2021-07-06 16:33:20
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2e667256a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 13 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8431734317343174, max_test_f1: 0.6571180820696747
count:13_repeat:2_time:2021-07-06 16:36:17
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2e667256a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 13 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8228782287822878, max_test_f1: 0.7005883069422935
count:14_repeat:0_time:2021-07-06 16:39:57
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f358c1c66a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 14 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8247232472324724, max_test_f1: 0.6667495854063019
count:14_repeat:1_time:2021-07-06 16:42:55
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f358c1c66a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 14 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8265682656826568, max_test_f1: 0.665163242809138
count:14_repeat:2_time:2021-07-06 16:46:50
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f358c1c66a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 14 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8413284132841329, max_test_f1: 0.692203504302172
count:15_repeat:0_time:2021-07-06 16:50:13
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe8527056a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 15 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8431734317343174, max_test_f1: 0.6724117233455095
count:15_repeat:1_time:2021-07-06 16:53:16
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe8527056a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 15 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8339483394833949, max_test_f1: 0.6806798522308753
count:15_repeat:2_time:2021-07-06 16:56:54
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe8527056a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 15 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8376383763837638, max_test_f1: 0.7180976956929827
count:16_repeat:0_time:2021-07-06 17:00:15
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7feffc74e6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 16 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6887341721823058
count:16_repeat:1_time:2021-07-06 17:04:37
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7feffc74e6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 16 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8450184501845018, max_test_f1: 0.7021374671187378
count:16_repeat:2_time:2021-07-06 17:09:11
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7feffc74e6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 16 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8487084870848709, max_test_f1: 0.6863174250461545
count:17_repeat:0_time:2021-07-06 17:12:32
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa507d396a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 17 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8302583025830258, max_test_f1: 0.6829648650954493
count:17_repeat:1_time:2021-07-06 17:16:11
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa507d396a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 17 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8431734317343174, max_test_f1: 0.6921529293113126
count:17_repeat:2_time:2021-07-06 17:20:07
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa507d396a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 17 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8487084870848709, max_test_f1: 0.7187620082173155
count:18_repeat:0_time:2021-07-06 17:26:10
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ffb40da06a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 18 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8431734317343174, max_test_f1: 0.6904636107643626
count:18_repeat:1_time:2021-07-06 17:30:42
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ffb40da06a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 18 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8339483394833949, max_test_f1: 0.6752681833581344
count:18_repeat:2_time:2021-07-06 17:33:51
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ffb40da06a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 18 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8302583025830258, max_test_f1: 0.6686700807345649
count:19_repeat:0_time:2021-07-06 17:36:50
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f62032586a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 19 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8376383763837638, max_test_f1: 0.7128985624262277
count:19_repeat:1_time:2021-07-06 17:39:50
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f62032586a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 19 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8394833948339483, max_test_f1: 0.6858387799564271
count:19_repeat:2_time:2021-07-06 17:43:41
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f62032586a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 19 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8413284132841329, max_test_f1: 0.7116885143570536
count:20_repeat:0_time:2021-07-06 17:47:58
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4f649586a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 20 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8431734317343174, max_test_f1: 0.6972889896699419
count:20_repeat:1_time:2021-07-06 17:51:05
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4f649586a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 20 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8505535055350554, max_test_f1: 0.6961347299708489
count:20_repeat:2_time:2021-07-06 17:54:28
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4f649586a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 20 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8284132841328413, max_test_f1: 0.6926137055623997
count:21_repeat:0_time:2021-07-06 17:57:57
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f700e4096a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 21 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8487084870848709, max_test_f1: 0.7002337694295205
count:21_repeat:1_time:2021-07-06 18:01:16
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f700e4096a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 21 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8523985239852399, max_test_f1: 0.6735422375871852
count:21_repeat:2_time:2021-07-06 18:04:04
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f700e4096a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 21 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8394833948339483, max_test_f1: 0.6924359683066151
count:22_repeat:0_time:2021-07-06 18:07:15
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5785ea26a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 22 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8523985239852399, max_test_f1: 0.7035567553709328
count:22_repeat:1_time:2021-07-06 18:10:21
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5785ea26a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 22 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8431734317343174, max_test_f1: 0.6759741428983003
count:22_repeat:2_time:2021-07-06 18:14:09
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5785ea26a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 22 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8321033210332104, max_test_f1: 0.6891848165013473
count:23_repeat:0_time:2021-07-06 18:17:51
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2a183306a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 23 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8468634686346863, max_test_f1: 0.722907077817022
count:23_repeat:1_time:2021-07-06 18:21:08
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2a183306a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 23 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8394833948339483, max_test_f1: 0.6878449010336665
count:23_repeat:2_time:2021-07-06 18:24:04
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2a183306a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 23 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8468634686346863, max_test_f1: 0.7129129129129129
count:24_repeat:0_time:2021-07-06 18:27:27
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f89464dc6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 24 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8413284132841329, max_test_f1: 0.6851867972823623
count:24_repeat:1_time:2021-07-06 18:31:03
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f89464dc6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 24 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8302583025830258, max_test_f1: 0.6741761639720824
count:24_repeat:2_time:2021-07-06 18:34:04
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f89464dc6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 24 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8284132841328413, max_test_f1: 0.7023522968423211
count:25_repeat:0_time:2021-07-06 18:37:28
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fccc6dc46a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 25 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8339483394833949, max_test_f1: 0.6614101291446479
count:25_repeat:1_time:2021-07-06 18:40:42
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fccc6dc46a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 25 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8339483394833949, max_test_f1: 0.6713739510402702
count:25_repeat:2_time:2021-07-06 18:43:42
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fccc6dc46a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 25 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8321033210332104, max_test_f1: 0.6740730825063658
count:26_repeat:0_time:2021-07-06 18:47:04
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff3de93d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 26 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8560885608856088, max_test_f1: 0.7051537098159041
count:26_repeat:1_time:2021-07-06 18:52:04
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff3de93d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 26 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8247232472324724, max_test_f1: 0.6581384114144478
count:26_repeat:2_time:2021-07-06 18:56:33
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff3de93d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 26 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8357933579335793, max_test_f1: 0.6979359590448052
count:27_repeat:0_time:2021-07-06 19:00:49
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbb745a46a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 27 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6890453275297861
count:27_repeat:1_time:2021-07-06 19:05:32
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbb745a46a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 27 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8357933579335793, max_test_f1: 0.6859920464604983
count:27_repeat:2_time:2021-07-06 19:09:36
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbb745a46a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 27 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8468634686346863, max_test_f1: 0.7186759293979429
count:28_repeat:0_time:2021-07-06 19:13:59
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8126826a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 28 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8339483394833949, max_test_f1: 0.6619515428722945
count:28_repeat:1_time:2021-07-06 19:17:18
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8126826a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 28 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8321033210332104, max_test_f1: 0.6689604550876226
count:28_repeat:2_time:2021-07-06 19:20:30
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8126826a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 28 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8376383763837638, max_test_f1: 0.7029001043242115
count:29_repeat:0_time:2021-07-06 19:26:19
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa3403526a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 29 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8321033210332104, max_test_f1: 0.6863962726682025
count:29_repeat:1_time:2021-07-06 19:30:28
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa3403526a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 29 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8376383763837638, max_test_f1: 0.6833082062782198
count:29_repeat:2_time:2021-07-06 19:33:52
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa3403526a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 29 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8376383763837638, max_test_f1: 0.6867965064686375
count:30_repeat:0_time:2021-07-06 19:37:16
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc01892f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 30 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8302583025830258, max_test_f1: 0.6837581046712655
count:30_repeat:1_time:2021-07-06 19:40:31
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc01892f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 30 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8394833948339483, max_test_f1: 0.6819477344904762
count:30_repeat:2_time:2021-07-06 19:43:33
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc01892f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 30 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8394833948339483, max_test_f1: 0.7035040879640025
count:31_repeat:0_time:2021-07-06 19:48:29
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5277f436a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 31 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8302583025830258, max_test_f1: 0.6740310570577335
count:31_repeat:1_time:2021-07-06 19:52:37
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5277f436a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 31 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8339483394833949, max_test_f1: 0.6721494124202607
count:31_repeat:2_time:2021-07-06 19:55:43
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5277f436a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 31 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8339483394833949, max_test_f1: 0.6708215832167738
count:32_repeat:0_time:2021-07-06 19:58:53
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4a096246a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 32 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6594242186869868
count:32_repeat:1_time:2021-07-06 20:03:58
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4a096246a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 32 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8357933579335793, max_test_f1: 0.6688968720899054
count:32_repeat:2_time:2021-07-06 20:07:11
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4a096246a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 32 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8339483394833949, max_test_f1: 0.6829184071289336
count:33_repeat:0_time:2021-07-06 20:10:03
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f938988f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 33 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8431734317343174, max_test_f1: 0.6846494691258703
count:33_repeat:1_time:2021-07-06 20:13:35
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f938988f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 33 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8247232472324724, max_test_f1: 0.6731972066624413
count:33_repeat:2_time:2021-07-06 20:17:29
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f938988f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 33 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8265682656826568, max_test_f1: 0.6906572354848217
count:34_repeat:0_time:2021-07-06 20:20:24
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f189d9a86a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 34 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6608619454751943
count:34_repeat:1_time:2021-07-06 20:23:20
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f189d9a86a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 34 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8247232472324724, max_test_f1: 0.6846779647531527
count:34_repeat:2_time:2021-07-06 20:26:26
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f189d9a86a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 34 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8450184501845018, max_test_f1: 0.7098252351403036
count:35_repeat:0_time:2021-07-06 20:29:32
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f33d81ab6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 35 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8357933579335793, max_test_f1: 0.6969848721961398
count:35_repeat:1_time:2021-07-06 20:33:56
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f33d81ab6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 35 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8376383763837638, max_test_f1: 0.6766801864978583
count:35_repeat:2_time:2021-07-06 20:36:44
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f33d81ab6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 3 count: 35 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8302583025830258, max_test_f1: 0.7131101539393813
count:36_repeat:0_time:2021-07-06 20:41:49
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f99f68556a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 36 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8302583025830258, max_test_f1: 0.6826267771025089
count:36_repeat:1_time:2021-07-06 20:44:28
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f99f68556a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 36 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8376383763837638, max_test_f1: 0.6925662151468602
count:36_repeat:2_time:2021-07-06 20:50:06
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f99f68556a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 36 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8394833948339483, max_test_f1: 0.6824434775254447
count:37_repeat:0_time:2021-07-06 20:52:33
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f92556066a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 37 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8431734317343174, max_test_f1: 0.6774328823100774
count:37_repeat:1_time:2021-07-06 20:55:19
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f92556066a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 37 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8450184501845018, max_test_f1: 0.6893612843074077
count:37_repeat:2_time:2021-07-06 20:57:59
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f92556066a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 37 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8376383763837638, max_test_f1: 0.7051178326843024
count:38_repeat:0_time:2021-07-06 21:01:48
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4126f5e6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 38 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8450184501845018, max_test_f1: 0.7052237842172323
count:38_repeat:1_time:2021-07-06 21:05:00
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4126f5e6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 38 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8376383763837638, max_test_f1: 0.722102595002676
count:38_repeat:2_time:2021-07-06 21:09:15
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4126f5e6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 38 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8450184501845018, max_test_f1: 0.7100356939901727
count:39_repeat:0_time:2021-07-06 21:13:51
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe9816a46a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 39 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8468634686346863, max_test_f1: 0.6907520834606843
count:39_repeat:1_time:2021-07-06 21:17:23
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe9816a46a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 39 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8284132841328413, max_test_f1: 0.6574338538341377
count:39_repeat:2_time:2021-07-06 21:20:10
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe9816a46a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 39 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8560885608856088, max_test_f1: 0.7020264452118461
count:40_repeat:0_time:2021-07-06 21:23:42
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd67fa0f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 40 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8487084870848709, max_test_f1: 0.7061591693320443
count:40_repeat:1_time:2021-07-06 21:26:34
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd67fa0f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 40 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8376383763837638, max_test_f1: 0.6884946855600313
count:40_repeat:2_time:2021-07-06 21:29:29
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd67fa0f6a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 40 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8450184501845018, max_test_f1: 0.7043120520881744
count:41_repeat:0_time:2021-07-06 21:32:47
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe338f1f6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 41 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8487084870848709, max_test_f1: 0.7087848273434417
count:41_repeat:1_time:2021-07-06 21:36:43
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe338f1f6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 41 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8228782287822878, max_test_f1: 0.6792863130530297
count:41_repeat:2_time:2021-07-06 21:39:30
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe338f1f6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 41 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8357933579335793, max_test_f1: 0.7016149137717766
count:42_repeat:0_time:2021-07-06 21:44:19
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f19db1ac6a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 42 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8487084870848709, max_test_f1: 0.6949060256513672
count:42_repeat:1_time:2021-07-06 21:48:16
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f19db1ac6a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 42 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8228782287822878, max_test_f1: 0.68024422168961
count:42_repeat:2_time:2021-07-06 21:50:58
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f19db1ac6a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 42 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8487084870848709, max_test_f1: 0.699233583544775
count:43_repeat:0_time:2021-07-06 21:54:44
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbfb12096a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 43 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8413284132841329, max_test_f1: 0.7018617803902991
count:43_repeat:1_time:2021-07-06 21:57:29
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbfb12096a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 43 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8284132841328413, max_test_f1: 0.6994133608905378
count:43_repeat:2_time:2021-07-06 22:00:12
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbfb12096a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 43 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8413284132841329, max_test_f1: 0.691215383286615
count:44_repeat:0_time:2021-07-06 22:04:04
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f94fc3ad6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 44 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8321033210332104, max_test_f1: 0.6529796403547631
count:44_repeat:1_time:2021-07-06 22:06:42
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f94fc3ad6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 44 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8265682656826568, max_test_f1: 0.6665427086688224
count:44_repeat:2_time:2021-07-06 22:09:36
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f94fc3ad6a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 44 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8413284132841329, max_test_f1: 0.6969982895377443
count:45_repeat:0_time:2021-07-06 22:13:15
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9a091206a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 45 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8505535055350554, max_test_f1: 0.669854304528695
count:45_repeat:1_time:2021-07-06 22:16:28
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9a091206a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 45 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8321033210332104, max_test_f1: 0.6869782397543839
count:45_repeat:2_time:2021-07-06 22:19:33
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9a091206a8> learning_rate: 1.4e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 45 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8468634686346863, max_test_f1: 0.7147385971979768
count:46_repeat:0_time:2021-07-06 22:22:48
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd0735c46a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 46 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8487084870848709, max_test_f1: 0.6939803886706541
count:46_repeat:1_time:2021-07-06 22:25:49
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd0735c46a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 46 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8413284132841329, max_test_f1: 0.6638594546255997
count:46_repeat:2_time:2021-07-06 22:29:06
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd0735c46a8> learning_rate: 1.4e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 46 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8487084870848709, max_test_f1: 0.7342591611616047
count:47_repeat:0_time:2021-07-06 22:33:05
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc3965e76a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 47 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8413284132841329, max_test_f1: 0.6957461214260708
count:47_repeat:1_time:2021-07-06 22:36:06
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc3965e76a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 47 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8265682656826568, max_test_f1: 0.6752609740175043
count:47_repeat:2_time:2021-07-06 22:38:46
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc3965e76a8> learning_rate: 1.4e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 47 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8431734317343174, max_test_f1: 0.7160833668050163
count:48_repeat:0_time:2021-07-06 22:42:26
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb92981f6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 48 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8413284132841329, max_test_f1: 0.6932212302160847
count:48_repeat:1_time:2021-07-06 22:45:54
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb92981f6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 48 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8376383763837638, max_test_f1: 0.6922508453766697
count:48_repeat:2_time:2021-07-06 22:48:22
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb92981f6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 48 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8394833948339483, max_test_f1: 0.7002389486260454
count:49_repeat:0_time:2021-07-06 22:51:28
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f26905496a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 49 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8413284132841329, max_test_f1: 0.7032252954408643
count:49_repeat:1_time:2021-07-06 22:54:17
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f26905496a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 49 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8431734317343174, max_test_f1: 0.69501174188273
count:49_repeat:2_time:2021-07-06 22:57:20
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f26905496a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 49 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8450184501845018, max_test_f1: 0.6998373696007549
count:50_repeat:0_time:2021-07-06 23:02:01
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2813fed6a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 50 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8560885608856088, max_test_f1: 0.6978008791800562
count:50_repeat:1_time:2021-07-06 23:05:11
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2813fed6a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 50 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8394833948339483, max_test_f1: 0.6802097694158356
count:50_repeat:2_time:2021-07-06 23:07:46
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2813fed6a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 50 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8376383763837638, max_test_f1: 0.710982668987492
count:51_repeat:0_time:2021-07-06 23:11:34
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f30e0dee6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 51 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8376383763837638, max_test_f1: 0.697701658957059
count:51_repeat:1_time:2021-07-06 23:15:32
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f30e0dee6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 51 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8413284132841329, max_test_f1: 0.7204812308404188
count:51_repeat:2_time:2021-07-06 23:18:42
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f30e0dee6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 51 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8376383763837638, max_test_f1: 0.6796953137936744
count:52_repeat:0_time:2021-07-06 23:22:48
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc9ab7bf6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 52 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8413284132841329, max_test_f1: 0.6940799467207674
count:52_repeat:1_time:2021-07-06 23:25:56
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc9ab7bf6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 52 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8247232472324724, max_test_f1: 0.6820898090267823
count:52_repeat:2_time:2021-07-06 23:29:01
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc9ab7bf6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 52 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8376383763837638, max_test_f1: 0.7251728165322694
count:53_repeat:0_time:2021-07-06 23:32:01
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb7ae6c96a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 53 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8321033210332104, max_test_f1: 0.6678402730603374
count:53_repeat:1_time:2021-07-06 23:34:26
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb7ae6c96a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 53 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8284132841328413, max_test_f1: 0.6788736155619272
count:53_repeat:2_time:2021-07-06 23:37:07
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb7ae6c96a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 53 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8431734317343174, max_test_f1: 0.7131711875282506
count:54_repeat:0_time:2021-07-06 23:40:49
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f49db82f6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 54 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8487084870848709, max_test_f1: 0.7053557773474353
count:54_repeat:1_time:2021-07-06 23:44:35
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f49db82f6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 54 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8487084870848709, max_test_f1: 0.6788124857598542
count:54_repeat:2_time:2021-07-06 23:47:07
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f49db82f6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 54 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8431734317343174, max_test_f1: 0.7161481383945009
count:55_repeat:0_time:2021-07-06 23:50:23
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f498157d6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 55 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8376383763837638, max_test_f1: 0.6901401874613348
count:55_repeat:1_time:2021-07-06 23:54:05
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f498157d6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 55 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8247232472324724, max_test_f1: 0.6583272101599857
count:55_repeat:2_time:2021-07-06 23:56:57
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f498157d6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 55 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8487084870848709, max_test_f1: 0.703277674706246
count:56_repeat:0_time:2021-07-07 00:00:35
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6e3bc906a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 56 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8450184501845018, max_test_f1: 0.7050559230784512
count:56_repeat:1_time:2021-07-07 00:03:46
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6e3bc906a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 56 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8191881918819188, max_test_f1: 0.672940979457584
count:56_repeat:2_time:2021-07-07 00:06:16
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6e3bc906a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 56 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8560885608856088, max_test_f1: 0.7247827965617816
count:57_repeat:0_time:2021-07-07 00:09:27
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6d1f43c6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 57 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8450184501845018, max_test_f1: 0.6786303710007572
count:57_repeat:1_time:2021-07-07 00:12:57
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6d1f43c6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 57 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8413284132841329, max_test_f1: 0.662182312130544
count:57_repeat:2_time:2021-07-07 00:15:19
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6d1f43c6a8> learning_rate: 1.2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 57 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8450184501845018, max_test_f1: 0.6997837524522917
count:58_repeat:0_time:2021-07-07 00:18:34
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f54b99fe6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 58 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8394833948339483, max_test_f1: 0.6874385449709134
count:58_repeat:1_time:2021-07-07 00:21:46
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f54b99fe6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 58 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 max_test_acc: 0.8321033210332104, max_test_f1: 0.6865807956717047
count:58_repeat:2_time:2021-07-07 00:24:17
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f54b99fe6a8> learning_rate: 1.2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 58 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 2 max_test_acc: 0.8321033210332104, max_test_f1: 0.7057676871918358
count:59_repeat:0_time:2021-07-07 00:27:43
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2c74afe6a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 59 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 0 max_test_acc: 0.8450184501845018, max_test_f1: 0.7070390647316019
count:59_repeat:1_time:2021-07-07 00:31:04
 model_name: EnsembleDB dataset: rest15 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2c74afe6a8> learning_rate: 1.2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 18 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 10 edge_type_number: 3 count: 59 dependency_type: ensemble redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['spacy', 'stanza', 'benepar'] repeat: 1 