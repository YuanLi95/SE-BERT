count:0_repeat:0_time:2021-07-15 15:50:55
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdbc37dc6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 0 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7711598746081505, max_test_f1: 0.7259054291037836
count:0_repeat:1_time:2021-07-15 15:54:48
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdbc37dc6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 0 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.774294670846395, max_test_f1: 0.7337052089805186
count:0_repeat:2_time:2021-07-15 16:00:28
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdbc37dc6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 0 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7789968652037618, max_test_f1: 0.7396251599217974
max_test_acc_avg: 0.7748171368861024, max_test_f1_avg: 0.7330785993353666

count:1_repeat:0_time:2021-07-15 16:04:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f868ead26a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 1 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7789968652037618, max_test_f1: 0.7481284611664547
count:1_repeat:1_time:2021-07-15 16:07:55
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f868ead26a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 1 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7412855660697656
count:1_repeat:2_time:2021-07-15 16:11:24
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f868ead26a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 1 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7758620689655172, max_test_f1: 0.7361919053648377
max_test_acc_avg: 0.7789968652037618, max_test_f1_avg: 0.7418686442003527

count:2_repeat:0_time:2021-07-15 16:15:01
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc06ce706a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 2 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7727272727272727, max_test_f1: 0.7320486631907244
count:2_repeat:1_time:2021-07-15 16:18:01
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc06ce706a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 2 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7915360501567398, max_test_f1: 0.7463792563658291
count:2_repeat:2_time:2021-07-15 16:21:32
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc06ce706a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 2 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7544002333562383
max_test_acc_avg: 0.7847439916405433, max_test_f1_avg: 0.7442760509709306

count:3_repeat:0_time:2021-07-15 16:25:13
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f503a13c6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 3 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7664576802507836, max_test_f1: 0.7238861391548523
count:3_repeat:1_time:2021-07-15 16:28:14
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f503a13c6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 3 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.786833855799373, max_test_f1: 0.7473621553884712
count:3_repeat:2_time:2021-07-15 16:33:35
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f503a13c6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 3 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7978056426332288, max_test_f1: 0.7551725200728817
max_test_acc_avg: 0.7836990595611285, max_test_f1_avg: 0.7421402715387351

count:4_repeat:0_time:2021-07-15 16:37:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdd1a45d6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 4 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7758620689655172, max_test_f1: 0.7350935571882248
count:4_repeat:1_time:2021-07-15 16:40:49
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdd1a45d6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 4 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7774294670846394, max_test_f1: 0.7396247835450361
count:4_repeat:2_time:2021-07-15 16:46:42
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fdd1a45d6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 4 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7490711364010001
max_test_acc_avg: 0.7795193312434692, max_test_f1_avg: 0.7412631590447537

count:5_repeat:0_time:2021-07-15 16:50:29
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f512667a6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 5 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7507820803802255
count:5_repeat:1_time:2021-07-15 16:56:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f512667a6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 5 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7491960248631448
count:5_repeat:2_time:2021-07-15 17:01:05
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f512667a6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 5 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.8040752351097179, max_test_f1: 0.7671429546429547
max_test_acc_avg: 0.7899686520376176, max_test_f1_avg: 0.7557070199621084

count:6_repeat:0_time:2021-07-15 17:06:07
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd5475146a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 6 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.768025078369906, max_test_f1: 0.7284567842416751
count:6_repeat:1_time:2021-07-15 17:09:15
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd5475146a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 6 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7915360501567398, max_test_f1: 0.7548068121616515
count:6_repeat:2_time:2021-07-15 17:15:26
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd5475146a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 6 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7789968652037618, max_test_f1: 0.7434611956738407
max_test_acc_avg: 0.7795193312434692, max_test_f1_avg: 0.7422415973590558

count:7_repeat:0_time:2021-07-15 17:19:19
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f89df4b06a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 7 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.774294670846395, max_test_f1: 0.7352642299292884
count:7_repeat:1_time:2021-07-15 17:22:24
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f89df4b06a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 7 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7504373992063421
count:7_repeat:2_time:2021-07-15 17:27:10
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f89df4b06a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 7 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7836990595611285, max_test_f1: 0.7392760686520199
max_test_acc_avg: 0.7800417972831766, max_test_f1_avg: 0.7416592325958834

count:8_repeat:0_time:2021-07-15 17:31:42
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f611ad0b6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 8 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.780564263322884, max_test_f1: 0.7410597364879438
count:8_repeat:1_time:2021-07-15 17:36:26
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f611ad0b6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 8 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7436883454427314
count:8_repeat:2_time:2021-07-15 17:40:06
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f611ad0b6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 8 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7821316614420063, max_test_f1: 0.7397934943407706
max_test_acc_avg: 0.7816091954022988, max_test_f1_avg: 0.7415138587571487

count:9_repeat:0_time:2021-07-15 17:44:12
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f782db436a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 9 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7774294670846394, max_test_f1: 0.7377205514093123
count:9_repeat:1_time:2021-07-15 17:49:17
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f782db436a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 9 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.780564263322884, max_test_f1: 0.7454694958694018
count:9_repeat:2_time:2021-07-15 17:53:10
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f782db436a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 9 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.7453001093614775
max_test_acc_avg: 0.7831765935214211, max_test_f1_avg: 0.7428300522133972

count:10_repeat:0_time:2021-07-15 17:58:03
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f17b2beb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 10 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.780564263322884, max_test_f1: 0.7495014015867687
count:10_repeat:1_time:2021-07-15 18:02:14
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f17b2beb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 10 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7774294670846394, max_test_f1: 0.7380131232341715
count:10_repeat:2_time:2021-07-15 18:06:21
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f17b2beb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 10 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7884012539184952, max_test_f1: 0.7567564684054532
max_test_acc_avg: 0.7821316614420063, max_test_f1_avg: 0.7480903310754644

count:11_repeat:0_time:2021-07-15 18:12:19
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe5fb9bb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 11 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7633228840125392, max_test_f1: 0.732542654592888
count:11_repeat:1_time:2021-07-15 18:15:28
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe5fb9bb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 11 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7884012539184952, max_test_f1: 0.7493164186154084
count:11_repeat:2_time:2021-07-15 18:19:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe5fb9bb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 11 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7405821747504683
max_test_acc_avg: 0.7789968652037618, max_test_f1_avg: 0.7408137493195882

count:12_repeat:0_time:2021-07-15 18:24:01
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5239eb66a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 12 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7695924764890282, max_test_f1: 0.7306855006160012
count:12_repeat:1_time:2021-07-15 18:27:11
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5239eb66a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 12 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7727272727272727, max_test_f1: 0.7326539800147147
count:12_repeat:2_time:2021-07-15 18:31:51
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f5239eb66a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 12 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7836990595611285, max_test_f1: 0.742307163055178
max_test_acc_avg: 0.7753396029258098, max_test_f1_avg: 0.7352155478952981

count:13_repeat:0_time:2021-07-15 18:35:25
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff6942396a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 13 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7758620689655172, max_test_f1: 0.7346144089257586
count:13_repeat:1_time:2021-07-15 18:39:34
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff6942396a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 13 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7475303473456826
count:13_repeat:2_time:2021-07-15 18:44:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff6942396a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 13 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7774294670846394, max_test_f1: 0.7414551039768513
max_test_acc_avg: 0.7789968652037618, max_test_f1_avg: 0.7411999534160975

count:14_repeat:0_time:2021-07-15 18:50:01
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb19a4836a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 14 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7711598746081505, max_test_f1: 0.7298905193763175
count:14_repeat:1_time:2021-07-15 18:53:05
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb19a4836a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 14 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7711598746081505, max_test_f1: 0.7360199127635513
count:14_repeat:2_time:2021-07-15 18:56:19
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb19a4836a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 14 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7489925894635836
max_test_acc_avg: 0.7758620689655172, max_test_f1_avg: 0.7383010072011508

count:15_repeat:0_time:2021-07-15 19:02:35
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f18e3f4a6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 15 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.780564263322884, max_test_f1: 0.7374941218155372
count:15_repeat:1_time:2021-07-15 19:06:17
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f18e3f4a6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 15 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7852664576802508, max_test_f1: 0.7473248808560381
count:15_repeat:2_time:2021-07-15 19:11:31
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f18e3f4a6a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 15 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.745840709724552
max_test_acc_avg: 0.7836990595611285, max_test_f1_avg: 0.7435532374653757

count:16_repeat:0_time:2021-07-15 19:16:03
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efed62696a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 16 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7789968652037618, max_test_f1: 0.7401904792748404
count:16_repeat:1_time:2021-07-15 19:19:44
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efed62696a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 16 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7470726708042221
count:16_repeat:2_time:2021-07-15 19:26:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efed62696a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 16 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7821316614420063, max_test_f1: 0.7509143113936307
max_test_acc_avg: 0.7816091954022988, max_test_f1_avg: 0.746059153824231

count:17_repeat:0_time:2021-07-15 19:30:46
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f36812e56a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 17 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7727272727272727, max_test_f1: 0.7324561403508771
count:17_repeat:1_time:2021-07-15 19:34:44
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f36812e56a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 17 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7852664576802508, max_test_f1: 0.7460842090298727
count:17_repeat:2_time:2021-07-15 19:39:56
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f36812e56a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 17 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7789968652037618, max_test_f1: 0.7409703455662981
max_test_acc_avg: 0.7789968652037618, max_test_f1_avg: 0.7398368983156827

count:18_repeat:0_time:2021-07-15 19:43:53
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f24320136a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 18 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.774294670846395, max_test_f1: 0.7360613436593996
count:18_repeat:1_time:2021-07-15 19:47:00
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f24320136a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 18 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7884012539184952, max_test_f1: 0.7459786931664668
count:18_repeat:2_time:2021-07-15 19:50:42
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f24320136a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 18 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7789968652037618, max_test_f1: 0.739182423944864
max_test_acc_avg: 0.780564263322884, max_test_f1_avg: 0.7404074869235768

count:19_repeat:0_time:2021-07-15 19:54:34
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f346c48d6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 19 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7836990595611285, max_test_f1: 0.7414152340120655
count:19_repeat:1_time:2021-07-15 19:59:34
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f346c48d6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 19 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7451429186824376
count:19_repeat:2_time:2021-07-15 20:03:12
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f346c48d6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 19 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.780564263322884, max_test_f1: 0.7445930610174093
max_test_acc_avg: 0.7821316614420063, max_test_f1_avg: 0.7437170712373042

count:20_repeat:0_time:2021-07-15 20:07:40
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb82cddb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 20 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7727272727272727, max_test_f1: 0.7349014724480153
count:20_repeat:1_time:2021-07-15 20:12:41
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb82cddb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 20 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7962382445141066, max_test_f1: 0.7631565924675664
count:20_repeat:2_time:2021-07-15 20:16:14
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb82cddb6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 20 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7836990595611285, max_test_f1: 0.7506018767557229
max_test_acc_avg: 0.7842215256008359, max_test_f1_avg: 0.7495533138904348

count:21_repeat:0_time:2021-07-15 20:20:46
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd4dcbd86a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 21 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.768025078369906, max_test_f1: 0.726478601541572
count:21_repeat:1_time:2021-07-15 20:25:46
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd4dcbd86a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 21 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7852664576802508, max_test_f1: 0.7519350755935253
count:21_repeat:2_time:2021-07-15 20:30:20
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd4dcbd86a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 21 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7821316614420063, max_test_f1: 0.7461325754810059
max_test_acc_avg: 0.7784743991640544, max_test_f1_avg: 0.7415154175387011

count:22_repeat:0_time:2021-07-15 20:34:12
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efddae1a6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 22 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7695924764890282, max_test_f1: 0.7284289716250966
count:22_repeat:1_time:2021-07-15 20:38:43
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efddae1a6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 22 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7789968652037618, max_test_f1: 0.7416048472191731
count:22_repeat:2_time:2021-07-15 20:43:52
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efddae1a6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 22 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.786833855799373, max_test_f1: 0.7505647349277496
max_test_acc_avg: 0.7784743991640543, max_test_f1_avg: 0.7401995179240064

count:23_repeat:0_time:2021-07-15 20:47:37
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f04231cb6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 23 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7789968652037618, max_test_f1: 0.74037998812382
count:23_repeat:1_time:2021-07-15 20:51:58
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f04231cb6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 23 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7727272727272727, max_test_f1: 0.7342281277449474
count:23_repeat:2_time:2021-07-15 20:55:24
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f04231cb6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 23 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.7534165450129408
max_test_acc_avg: 0.7810867293625914, max_test_f1_avg: 0.7426748869605694

count:24_repeat:0_time:2021-07-15 20:59:34
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa7f09f86a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 24 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7774294670846394, max_test_f1: 0.7401209390041994
count:24_repeat:1_time:2021-07-15 21:04:20
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa7f09f86a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 24 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7899686520376176, max_test_f1: 0.7555289040597404
count:24_repeat:2_time:2021-07-15 21:09:40
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa7f09f86a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 24 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7789968652037618, max_test_f1: 0.7465686826516299
max_test_acc_avg: 0.7821316614420063, max_test_f1_avg: 0.7474061752385232

count:25_repeat:0_time:2021-07-15 21:13:47
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8511926a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 25 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7664576802507836, max_test_f1: 0.727796343900159
count:25_repeat:1_time:2021-07-15 21:17:14
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8511926a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 25 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.780564263322884, max_test_f1: 0.743557450206969
count:25_repeat:2_time:2021-07-15 21:21:06
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8511926a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 25 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7774294670846394, max_test_f1: 0.742209371350539
max_test_acc_avg: 0.7748171368861024, max_test_f1_avg: 0.7378543884858889

count:26_repeat:0_time:2021-07-15 21:24:50
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc06a0f46a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 26 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7648902821316614, max_test_f1: 0.7347754451381544
count:26_repeat:1_time:2021-07-15 21:27:47
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc06a0f46a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 26 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.786833855799373, max_test_f1: 0.7455387410061953
count:26_repeat:2_time:2021-07-15 21:30:44
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc06a0f46a8> learning_rate: 2e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 26 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.7574434231132982
max_test_acc_avg: 0.7810867293625914, max_test_f1_avg: 0.7459192030858826

count:27_repeat:0_time:2021-07-15 21:35:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f470e3e66a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 27 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7758620689655172, max_test_f1: 0.7399814718859421
count:27_repeat:1_time:2021-07-15 21:39:20
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f470e3e66a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 27 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7852664576802508, max_test_f1: 0.7525867611468319
count:27_repeat:2_time:2021-07-15 21:43:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f470e3e66a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 27 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.755014336407175
max_test_acc_avg: 0.7842215256008359, max_test_f1_avg: 0.7491941898133163

count:28_repeat:0_time:2021-07-15 21:47:32
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbd42bc16a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 28 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7836990595611285, max_test_f1: 0.7469094194021185
count:28_repeat:1_time:2021-07-15 21:51:55
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbd42bc16a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 28 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7492551402696245
count:28_repeat:2_time:2021-07-15 21:56:43
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbd42bc16a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 28 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7571166647161668
max_test_acc_avg: 0.7852664576802507, max_test_f1_avg: 0.7510937414626366

count:29_repeat:0_time:2021-07-15 22:02:37
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe677fc96a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 29 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7836990595611285, max_test_f1: 0.7481657794157793
count:29_repeat:1_time:2021-07-15 22:06:04
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe677fc96a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 29 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7472244529695705
count:29_repeat:2_time:2021-07-15 22:09:32
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fe677fc96a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 29 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7533097871962328
max_test_acc_avg: 0.7836990595611285, max_test_f1_avg: 0.7495666731938608

count:30_repeat:0_time:2021-07-15 22:16:11
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fcb6022d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 30 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.774294670846395, max_test_f1: 0.740711757957869
count:30_repeat:1_time:2021-07-15 22:19:13
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fcb6022d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 30 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.786833855799373, max_test_f1: 0.7518069536443805
count:30_repeat:2_time:2021-07-15 22:24:14
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fcb6022d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 30 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7978056426332288, max_test_f1: 0.7637214640674203
max_test_acc_avg: 0.7863113897596655, max_test_f1_avg: 0.7520800585565567

count:31_repeat:0_time:2021-07-15 22:28:30
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8213fb6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 31 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7836990595611285, max_test_f1: 0.7375116294469487
count:31_repeat:1_time:2021-07-15 22:32:31
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8213fb6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 31 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.745875189848189
count:31_repeat:2_time:2021-07-15 22:36:54
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff8213fb6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 31 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7475640186466217
max_test_acc_avg: 0.7842215256008359, max_test_f1_avg: 0.7436502793139198

count:32_repeat:0_time:2021-07-15 22:41:38
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd5a45496a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 32 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7466424123488884
count:32_repeat:1_time:2021-07-15 22:46:02
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd5a45496a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 32 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7711598746081505, max_test_f1: 0.7370639916076579
count:32_repeat:2_time:2021-07-15 22:49:30
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd5a45496a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 32 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.757795424768067
max_test_acc_avg: 0.7816091954022989, max_test_f1_avg: 0.7471672762415378

count:33_repeat:0_time:2021-07-15 22:53:46
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa854cee6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 33 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7428820451595506
count:33_repeat:1_time:2021-07-15 22:57:26
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa854cee6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 33 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.746092136875923
count:33_repeat:2_time:2021-07-15 23:01:12
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa854cee6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 33 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.786833855799373, max_test_f1: 0.7539812602228649
max_test_acc_avg: 0.7836990595611285, max_test_f1_avg: 0.7476518140861129

count:34_repeat:0_time:2021-07-15 23:06:05
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f81860226a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 34 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.786833855799373, max_test_f1: 0.7428643097823144
count:34_repeat:1_time:2021-07-15 23:09:41
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f81860226a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 34 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7446373109328576
count:34_repeat:2_time:2021-07-15 23:13:41
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f81860226a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 34 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7440408103743975
max_test_acc_avg: 0.7847439916405433, max_test_f1_avg: 0.7438474770298565

count:35_repeat:0_time:2021-07-15 23:17:56
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f606fb6f6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 35 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7537199783983892
count:35_repeat:1_time:2021-07-15 23:21:56
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f606fb6f6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 35 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.8072100313479624, max_test_f1: 0.7692737425619406
count:35_repeat:2_time:2021-07-15 23:25:27
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f606fb6f6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 35 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.7517117571762381
max_test_acc_avg: 0.7957157784743991, max_test_f1_avg: 0.7582351593788559

count:36_repeat:0_time:2021-07-15 23:31:03
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2fc24576a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 36 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7457110086559541
count:36_repeat:1_time:2021-07-15 23:34:59
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2fc24576a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 36 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7484080774568658
count:36_repeat:2_time:2021-07-15 23:38:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2fc24576a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 36 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7559727559588035
max_test_acc_avg: 0.7852664576802507, max_test_f1_avg: 0.7500306140238745

count:37_repeat:0_time:2021-07-15 23:43:13
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fddb7b9c6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 37 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7899686520376176, max_test_f1: 0.7546939862505547
count:37_repeat:1_time:2021-07-15 23:47:07
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fddb7b9c6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 37 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7915360501567398, max_test_f1: 0.7577261799847724
count:37_repeat:2_time:2021-07-15 23:51:09
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fddb7b9c6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 37 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.8009404388714734, max_test_f1: 0.7650323418434005
max_test_acc_avg: 0.7941483803552769, max_test_f1_avg: 0.7591508360262426

count:38_repeat:0_time:2021-07-15 23:55:24
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb85fe266a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 38 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7727272727272727, max_test_f1: 0.737122736418511
count:38_repeat:1_time:2021-07-15 23:59:25
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb85fe266a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 38 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7899686520376176, max_test_f1: 0.7526898850764994
count:38_repeat:2_time:2021-07-16 00:04:21
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb85fe266a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 38 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7884012539184952, max_test_f1: 0.748843589412695
max_test_acc_avg: 0.7836990595611285, max_test_f1_avg: 0.7462187369692351

count:39_repeat:0_time:2021-07-16 00:08:06
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fda8c0366a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 39 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7899686520376176, max_test_f1: 0.7513187991363383
count:39_repeat:1_time:2021-07-16 00:11:40
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fda8c0366a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 39 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7464869284678528
count:39_repeat:2_time:2021-07-16 00:15:51
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fda8c0366a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 39 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7448081859710619
max_test_acc_avg: 0.7857889237199581, max_test_f1_avg: 0.747537971191751

count:40_repeat:0_time:2021-07-16 00:20:07
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9e3a58d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 40 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7774294670846394, max_test_f1: 0.7370822088418655
count:40_repeat:1_time:2021-07-16 00:23:54
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9e3a58d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 40 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7412016015590486
count:40_repeat:2_time:2021-07-16 00:28:02
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9e3a58d6a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 40 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7500700820853184
max_test_acc_avg: 0.7836990595611285, max_test_f1_avg: 0.7427846308287442

count:41_repeat:0_time:2021-07-16 00:32:32
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a937c56a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 41 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7476190476190476
count:41_repeat:1_time:2021-07-16 00:36:11
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a937c56a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 41 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7884012539184952, max_test_f1: 0.748690625565731
count:41_repeat:2_time:2021-07-16 00:40:59
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1a937c56a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 41 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7503975526445273
max_test_acc_avg: 0.7868338557993731, max_test_f1_avg: 0.7489024086097688

count:42_repeat:0_time:2021-07-16 00:47:13
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efded0266a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 42 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7515653926852347
count:42_repeat:1_time:2021-07-16 00:51:08
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efded0266a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 42 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7978056426332288, max_test_f1: 0.7631348804913234
count:42_repeat:2_time:2021-07-16 00:55:10
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7efded0266a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 42 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7581245235508577
max_test_acc_avg: 0.7920585161964473, max_test_f1_avg: 0.7576082655758053

count:43_repeat:0_time:2021-07-16 00:59:12
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f765fc036a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 43 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7946708463949843, max_test_f1: 0.7511744376151156
count:43_repeat:1_time:2021-07-16 01:03:03
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f765fc036a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 43 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7475397041719015
count:43_repeat:2_time:2021-07-16 01:06:15
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f765fc036a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 43 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.786833855799373, max_test_f1: 0.7461180702524818
max_test_acc_avg: 0.7884012539184951, max_test_f1_avg: 0.7482774040131663

count:44_repeat:0_time:2021-07-16 01:10:03
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f331224c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 44 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7899686520376176, max_test_f1: 0.747166635425021
count:44_repeat:1_time:2021-07-16 01:14:23
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f331224c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 44 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7789968652037618, max_test_f1: 0.7442007086687955
count:44_repeat:2_time:2021-07-16 01:18:32
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f331224c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 44 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.8025078369905956, max_test_f1: 0.7642935191846393
max_test_acc_avg: 0.7904911180773251, max_test_f1_avg: 0.7518869544261518

count:45_repeat:0_time:2021-07-16 01:23:10
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9e1bd9e6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 45 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7727272727272727, max_test_f1: 0.7401383324788805
count:45_repeat:1_time:2021-07-16 01:26:31
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9e1bd9e6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 45 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7852664576802508, max_test_f1: 0.7450523901102025
count:45_repeat:2_time:2021-07-16 01:31:15
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f9e1bd9e6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 45 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7962382445141066, max_test_f1: 0.75680771100397
max_test_acc_avg: 0.7847439916405433, max_test_f1_avg: 0.7473328111976844

count:46_repeat:0_time:2021-07-16 01:36:42
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f22313976a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 46 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.774294670846395, max_test_f1: 0.7396442328071281
count:46_repeat:1_time:2021-07-16 01:39:54
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f22313976a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 46 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7821316614420063, max_test_f1: 0.7426009740212266
count:46_repeat:2_time:2021-07-16 01:43:09
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f22313976a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 46 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7516289149618235
max_test_acc_avg: 0.7805642633228841, max_test_f1_avg: 0.7446247072633927

count:47_repeat:0_time:2021-07-16 01:47:18
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1c3bb7b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 47 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7852664576802508, max_test_f1: 0.7533891323641985
count:47_repeat:1_time:2021-07-16 01:50:35
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1c3bb7b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 47 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7758620689655172, max_test_f1: 0.7367264314632737
count:47_repeat:2_time:2021-07-16 01:54:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1c3bb7b6a8> learning_rate: 1.5e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 47 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7470266855520312
max_test_acc_avg: 0.7836990595611285, max_test_f1_avg: 0.7457140831265011

count:48_repeat:0_time:2021-07-16 01:59:44
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f42968e16a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 48 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7789968652037618, max_test_f1: 0.7408051211724579
count:48_repeat:1_time:2021-07-16 02:03:03
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f42968e16a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 48 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.780564263322884, max_test_f1: 0.7434599516183081
count:48_repeat:2_time:2021-07-16 02:06:47
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f42968e16a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 48 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.750077897997369
max_test_acc_avg: 0.7816091954022989, max_test_f1_avg: 0.7447809902627117

count:49_repeat:0_time:2021-07-16 02:10:08
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f97568a76a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 49 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.780564263322884, max_test_f1: 0.7469733461540935
count:49_repeat:1_time:2021-07-16 02:14:51
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f97568a76a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 49 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7931034482758621, max_test_f1: 0.7569578135013049
count:49_repeat:2_time:2021-07-16 02:19:10
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f97568a76a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 49 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7441770935521421
max_test_acc_avg: 0.7863113897596655, max_test_f1_avg: 0.7493694177358469

count:50_repeat:0_time:2021-07-16 02:25:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc03aaf06a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 50 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.786833855799373, max_test_f1: 0.750746294233965
count:50_repeat:1_time:2021-07-16 02:29:08
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc03aaf06a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 50 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7931034482758621, max_test_f1: 0.7584299082666965
count:50_repeat:2_time:2021-07-16 02:33:33
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fc03aaf06a8> learning_rate: 1.5e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 50 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.7534128822646678
max_test_acc_avg: 0.790491118077325, max_test_f1_avg: 0.7541963615884432

count:51_repeat:0_time:2021-07-16 02:36:56
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f146f06b6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 51 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7456545377163525
count:51_repeat:1_time:2021-07-16 02:41:08
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f146f06b6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 51 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.780564263322884, max_test_f1: 0.747752144581013
count:51_repeat:2_time:2021-07-16 02:44:48
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f146f06b6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 51 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.786833855799373, max_test_f1: 0.7507115865927272
max_test_acc_avg: 0.7831765935214211, max_test_f1_avg: 0.7480394229633642

count:52_repeat:0_time:2021-07-16 02:50:38
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1474e996a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 52 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7852664576802508, max_test_f1: 0.7494108653144455
count:52_repeat:1_time:2021-07-16 02:54:54
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1474e996a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 52 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7915360501567398, max_test_f1: 0.7569960310930361
count:52_repeat:2_time:2021-07-16 02:59:10
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f1474e996a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 52 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7884012539184952, max_test_f1: 0.7608163768652115
max_test_acc_avg: 0.7884012539184951, max_test_f1_avg: 0.7557410910908978

count:53_repeat:0_time:2021-07-16 03:03:45
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f839245c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 53 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7789968652037618, max_test_f1: 0.7491159270725835
count:53_repeat:1_time:2021-07-16 03:07:04
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f839245c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 53 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7451932452683007
count:53_repeat:2_time:2021-07-16 03:10:20
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f839245c6a8> learning_rate: 1.5e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 53 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7836990595611285, max_test_f1: 0.7494313313638692
max_test_acc_avg: 0.7821316614420062, max_test_f1_avg: 0.7479135012349177

count:54_repeat:0_time:2021-07-16 03:14:33
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4c3919f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 54 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7836990595611285, max_test_f1: 0.7447043979331974
count:54_repeat:1_time:2021-07-16 03:18:52
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4c3919f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 54 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7915360501567398, max_test_f1: 0.7564099947329628
count:54_repeat:2_time:2021-07-16 03:23:14
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f4c3919f6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 54 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7821316614420063, max_test_f1: 0.7407997389036246
max_test_acc_avg: 0.7857889237199581, max_test_f1_avg: 0.7473047105232616

count:55_repeat:0_time:2021-07-16 03:27:48
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa42a2a56a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 55 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.786833855799373, max_test_f1: 0.7518902148171862
count:55_repeat:1_time:2021-07-16 03:32:01
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa42a2a56a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 55 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7931034482758621, max_test_f1: 0.7532060241960585
count:55_repeat:2_time:2021-07-16 03:36:13
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa42a2a56a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 55 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7453389720914271
max_test_acc_avg: 0.7884012539184954, max_test_f1_avg: 0.750145070368224

count:56_repeat:0_time:2021-07-16 03:42:38
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa54cade6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 56 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.786833855799373, max_test_f1: 0.7546215655077816
count:56_repeat:1_time:2021-07-16 03:45:58
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa54cade6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 56 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7978056426332288, max_test_f1: 0.7589915863053017
count:56_repeat:2_time:2021-07-16 03:50:44
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa54cade6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 56 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7962382445141066, max_test_f1: 0.7576215160393659
max_test_acc_avg: 0.7936259143155695, max_test_f1_avg: 0.757078222617483

count:57_repeat:0_time:2021-07-16 03:58:08
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7e5906e6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 57 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.786833855799373, max_test_f1: 0.7575355503038179
count:57_repeat:1_time:2021-07-16 04:01:30
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7e5906e6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 57 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7899686520376176, max_test_f1: 0.7548491315834026
count:57_repeat:2_time:2021-07-16 04:04:49
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7e5906e6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 57 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7617755510861448
max_test_acc_avg: 0.7889237199582028, max_test_f1_avg: 0.7580534109911218

count:58_repeat:0_time:2021-07-16 04:09:05
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbd6c94d6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 58 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7789968652037618, max_test_f1: 0.7435697162219027
count:58_repeat:1_time:2021-07-16 04:12:26
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbd6c94d6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 58 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7915360501567398, max_test_f1: 0.7525474680981845
count:58_repeat:2_time:2021-07-16 04:16:40
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fbd6c94d6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 58 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.7530077463083998
max_test_acc_avg: 0.7873563218390806, max_test_f1_avg: 0.7497083102094956

count:59_repeat:0_time:2021-07-16 04:21:25
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f38d2c0c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 59 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7836990595611285, max_test_f1: 0.7537984555111699
count:59_repeat:1_time:2021-07-16 04:24:39
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f38d2c0c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 59 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7946708463949843, max_test_f1: 0.7611430553895815
count:59_repeat:2_time:2021-07-16 04:28:23
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f38d2c0c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 59 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7962382445141066, max_test_f1: 0.7594408399492588
max_test_acc_avg: 0.7915360501567398, max_test_f1_avg: 0.7581274502833367

count:60_repeat:0_time:2021-07-16 04:33:01
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fadcd89d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 60 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7789968652037618, max_test_f1: 0.7435057533070287
count:60_repeat:1_time:2021-07-16 04:36:14
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fadcd89d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 60 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7978056426332288, max_test_f1: 0.7654496331092076
count:60_repeat:2_time:2021-07-16 04:40:56
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fadcd89d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 60 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7491677945941513
max_test_acc_avg: 0.7889237199582028, max_test_f1_avg: 0.7527077270034624

count:61_repeat:0_time:2021-07-16 04:46:27
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07c769d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 61 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7512070578081369
count:61_repeat:1_time:2021-07-16 04:52:32
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07c769d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 61 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7962382445141066, max_test_f1: 0.7608508636077559
count:61_repeat:2_time:2021-07-16 04:56:23
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07c769d6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 61 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.786833855799373, max_test_f1: 0.7477965298607848
max_test_acc_avg: 0.7904911180773251, max_test_f1_avg: 0.7532848170922258

count:62_repeat:0_time:2021-07-16 05:00:28
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb4a94306a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 62 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.786833855799373, max_test_f1: 0.7574470012240822
count:62_repeat:1_time:2021-07-16 05:03:44
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb4a94306a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 62 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7899686520376176, max_test_f1: 0.7539208922611266
count:62_repeat:2_time:2021-07-16 05:08:27
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fb4a94306a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 62 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.786833855799373, max_test_f1: 0.7494430389343046
max_test_acc_avg: 0.7878787878787877, max_test_f1_avg: 0.7536036441398378

count:63_repeat:0_time:2021-07-16 05:13:06
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f920c1766a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 63 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7915360501567398, max_test_f1: 0.7598224552041254
count:63_repeat:1_time:2021-07-16 05:16:25
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f920c1766a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 63 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7915360501567398, max_test_f1: 0.7560945273948465
count:63_repeat:2_time:2021-07-16 05:20:11
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f920c1766a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 63 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7931034482758621, max_test_f1: 0.7514876818417499
max_test_acc_avg: 0.7920585161964473, max_test_f1_avg: 0.7558015548135738

count:64_repeat:0_time:2021-07-16 05:25:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3efd4156a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 64 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7852664576802508, max_test_f1: 0.7467486305227627
count:64_repeat:1_time:2021-07-16 05:28:40
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3efd4156a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 64 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7978056426332288, max_test_f1: 0.7636838317282012
count:64_repeat:2_time:2021-07-16 05:32:58
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3efd4156a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 64 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7493049271494675
max_test_acc_avg: 0.7910135841170325, max_test_f1_avg: 0.7532457964668104

count:65_repeat:0_time:2021-07-16 05:37:38
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2e5cc136a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 65 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7541364639142767
count:65_repeat:1_time:2021-07-16 05:40:53
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2e5cc136a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 65 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7884012539184952, max_test_f1: 0.7526431901431901
count:65_repeat:2_time:2021-07-16 05:44:08
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f2e5cc136a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 65 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.755430248061827
max_test_acc_avg: 0.7894461859979102, max_test_f1_avg: 0.754069967373098

count:66_repeat:0_time:2021-07-16 05:48:22
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f16a391c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 66 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7511176153426611
count:66_repeat:1_time:2021-07-16 05:51:44
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f16a391c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 66 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7931034482758621, max_test_f1: 0.7571010323477753
count:66_repeat:2_time:2021-07-16 05:56:03
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f16a391c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 66 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7523146014953523
max_test_acc_avg: 0.790491118077325, max_test_f1_avg: 0.7535110830619295

count:67_repeat:0_time:2021-07-16 06:00:42
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa86e8976a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 67 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7931034482758621, max_test_f1: 0.7610388892177746
count:67_repeat:1_time:2021-07-16 06:04:02
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa86e8976a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 67 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7458646805603636
count:67_repeat:2_time:2021-07-16 06:08:24
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa86e8976a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 67 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7946708463949843, max_test_f1: 0.7544827057022179
max_test_acc_avg: 0.790491118077325, max_test_f1_avg: 0.7537954251601188

count:68_repeat:0_time:2021-07-16 06:13:19
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f79bfbc96a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 68 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7899686520376176, max_test_f1: 0.754668120485212
count:68_repeat:1_time:2021-07-16 06:18:06
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f79bfbc96a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 68 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7852664576802508, max_test_f1: 0.7473598521108031
count:68_repeat:2_time:2021-07-16 06:21:53
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f79bfbc96a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 68 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7789968652037618, max_test_f1: 0.7395024002408349
max_test_acc_avg: 0.7847439916405433, max_test_f1_avg: 0.7471767909456167

count:69_repeat:0_time:2021-07-16 06:26:48
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07c0ca56a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 69 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7589154770081868
count:69_repeat:1_time:2021-07-16 06:30:05
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07c0ca56a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 69 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7931034482758621, max_test_f1: 0.7493943306892947
count:69_repeat:2_time:2021-07-16 06:34:52
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07c0ca56a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 69 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.799373040752351, max_test_f1: 0.7579154639607081
max_test_acc_avg: 0.7936259143155695, max_test_f1_avg: 0.7554084238860632

count:70_repeat:0_time:2021-07-16 06:39:29
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff45149e6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 70 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7852664576802508, max_test_f1: 0.7549142205280587
count:70_repeat:1_time:2021-07-16 06:42:48
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff45149e6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 70 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.786833855799373, max_test_f1: 0.7483008060268247
count:70_repeat:2_time:2021-07-16 06:46:36
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7ff45149e6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 70 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7946708463949843, max_test_f1: 0.7544307685943811
max_test_acc_avg: 0.7889237199582028, max_test_f1_avg: 0.7525485983830881

count:71_repeat:0_time:2021-07-16 06:51:12
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa8518d86a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 71 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7962382445141066, max_test_f1: 0.7586583556434396
count:71_repeat:1_time:2021-07-16 06:54:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa8518d86a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 71 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7453897148639942
count:71_repeat:2_time:2021-07-16 06:59:24
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa8518d86a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.5 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 71 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7978056426332288, max_test_f1: 0.7621246757383653
max_test_acc_avg: 0.7925809822361547, max_test_f1_avg: 0.7553909154152664

count:72_repeat:0_time:2021-07-16 07:03:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa36d7bd6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 72 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7493625699817966
count:72_repeat:1_time:2021-07-16 07:07:18
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa36d7bd6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 72 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7931034482758621, max_test_f1: 0.7581129490666939
count:72_repeat:2_time:2021-07-16 07:10:31
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fa36d7bd6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 72 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7931034482758621, max_test_f1: 0.7595720690764471
max_test_acc_avg: 0.7894461859979102, max_test_f1_avg: 0.7556825293749793

count:73_repeat:0_time:2021-07-16 07:15:10
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07f30466a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 73 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.780564263322884, max_test_f1: 0.7461442195955471
count:73_repeat:1_time:2021-07-16 07:19:28
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07f30466a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 73 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7852664576802508, max_test_f1: 0.7477789360034285
count:73_repeat:2_time:2021-07-16 07:23:39
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f07f30466a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 73 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.786833855799373, max_test_f1: 0.7514183576770973
max_test_acc_avg: 0.7842215256008359, max_test_f1_avg: 0.7484471710920243

count:74_repeat:0_time:2021-07-16 07:29:56
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f738335e6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 74 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7758620689655172, max_test_f1: 0.7405416906899487
count:74_repeat:1_time:2021-07-16 07:33:04
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f738335e6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 74 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7946708463949843, max_test_f1: 0.7533057930601564
count:74_repeat:2_time:2021-07-16 07:36:35
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f738335e6a8> learning_rate: 1e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 74 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7931034482758621, max_test_f1: 0.7559646881962102
max_test_acc_avg: 0.787878787878788, max_test_f1_avg: 0.7499373906487717

count:75_repeat:0_time:2021-07-16 07:40:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd643d666a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 75 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.752454121487875
count:75_repeat:1_time:2021-07-16 07:44:18
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd643d666a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 75 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7946708463949843, max_test_f1: 0.7576818022990426
count:75_repeat:2_time:2021-07-16 07:48:39
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7fd643d666a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 75 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7511091059478155
max_test_acc_avg: 0.7889237199582028, max_test_f1_avg: 0.753748343244911

count:76_repeat:0_time:2021-07-16 07:53:47
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6db149c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 76 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.780564263322884, max_test_f1: 0.7496498475524901
count:76_repeat:1_time:2021-07-16 07:57:06
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6db149c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 76 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7946708463949843, max_test_f1: 0.7592469830681213
count:76_repeat:2_time:2021-07-16 08:01:54
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6db149c6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 76 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7978056426332288, max_test_f1: 0.7627047419791425
max_test_acc_avg: 0.7910135841170324, max_test_f1_avg: 0.7572005241999179

count:77_repeat:0_time:2021-07-16 08:09:16
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f759111b6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 77 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7852664576802508, max_test_f1: 0.748325281901539
count:77_repeat:1_time:2021-07-16 08:12:38
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f759111b6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 77 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7978056426332288, max_test_f1: 0.7595272620047209
count:77_repeat:2_time:2021-07-16 08:16:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f759111b6a8> learning_rate: 1e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 77 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7565422083732077
max_test_acc_avg: 0.7910135841170325, max_test_f1_avg: 0.7547982507598224

count:78_repeat:0_time:2021-07-16 08:21:36
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f141cd736a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 78 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7519015106237813
count:78_repeat:1_time:2021-07-16 08:24:56
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f141cd736a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 78 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7931034482758621, max_test_f1: 0.7540013279217131
count:78_repeat:2_time:2021-07-16 08:29:15
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f141cd736a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 78 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.786833855799373, max_test_f1: 0.7477874847609479
max_test_acc_avg: 0.7873563218390803, max_test_f1_avg: 0.751230107768814

count:79_repeat:0_time:2021-07-16 08:34:03
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7c5292c6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 79 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7601538976028973
count:79_repeat:1_time:2021-07-16 08:37:25
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7c5292c6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 79 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.8009404388714734, max_test_f1: 0.7634774934525294
count:79_repeat:2_time:2021-07-16 08:41:39
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f7c5292c6a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 79 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7497217489704493
max_test_acc_avg: 0.7915360501567399, max_test_f1_avg: 0.7577843800086254

count:80_repeat:0_time:2021-07-16 08:46:40
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f87a9dc26a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 80 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7915360501567398, max_test_f1: 0.7614174972314508
count:80_repeat:1_time:2021-07-16 08:49:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f87a9dc26a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 80 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7946708463949843, max_test_f1: 0.7623515470386827
count:80_repeat:2_time:2021-07-16 08:54:32
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f87a9dc26a8> learning_rate: 1e-05 l2reg: 0.0001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 1.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 edge_type_number: 2 count: 80 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7915360501567398, max_test_f1: 0.7540102281410581
max_test_acc_avg: 0.7925809822361547, max_test_f1_avg: 0.7592597574703972

count:81_repeat:0_time:2021-07-16 08:59:11
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6488c986a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 81 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7915360501567398, max_test_f1: 0.7591083239014851
count:81_repeat:1_time:2021-07-16 09:03:18
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6488c986a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 81 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7946708463949843, max_test_f1: 0.7517626305779884
count:81_repeat:2_time:2021-07-16 09:08:11
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6488c986a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 81 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7789968652037618, max_test_f1: 0.7452071046977636
max_test_acc_avg: 0.7884012539184954, max_test_f1_avg: 0.7520260197257457

count:82_repeat:0_time:2021-07-16 09:12:57
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f87d73616a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 82 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7513564640786834
count:82_repeat:1_time:2021-07-16 09:16:25
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f87d73616a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 82 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7789968652037618, max_test_f1: 0.7382349089991358
count:82_repeat:2_time:2021-07-16 09:20:14
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f87d73616a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 82 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7899686520376176, max_test_f1: 0.7425301628691457
max_test_acc_avg: 0.7857889237199581, max_test_f1_avg: 0.7440405119823216

count:83_repeat:0_time:2021-07-16 09:24:02
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f070f61f6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 83 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7774294670846394, max_test_f1: 0.7407671258531431
count:83_repeat:1_time:2021-07-16 09:28:26
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f070f61f6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 83 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7727272727272727, max_test_f1: 0.7375471301520548
count:83_repeat:2_time:2021-07-16 09:31:55
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f070f61f6a8> learning_rate: 2e-05 l2reg: 0.01 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 83 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7852664576802508, max_test_f1: 0.7517895053895175
max_test_acc_avg: 0.7784743991640543, max_test_f1_avg: 0.7433679204649052

count:84_repeat:0_time:2021-07-16 09:38:19
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f53ca2806a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 84 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7427588026104585
count:84_repeat:1_time:2021-07-16 09:42:16
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f53ca2806a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 84 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7789968652037618, max_test_f1: 0.7365486116296239
count:84_repeat:2_time:2021-07-16 09:47:02
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f53ca2806a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 84 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.799373040752351, max_test_f1: 0.7676244463186044
max_test_acc_avg: 0.7868338557993729, max_test_f1_avg: 0.7489772868528956

count:85_repeat:0_time:2021-07-16 09:50:47
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3855ca76a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 85 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7884012539184952, max_test_f1: 0.7540472474825891
count:85_repeat:1_time:2021-07-16 09:54:25
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3855ca76a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 85 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7836990595611285, max_test_f1: 0.7450922633020044
count:85_repeat:2_time:2021-07-16 09:57:34
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f3855ca76a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 85 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.7774294670846394, max_test_f1: 0.7388748565040318
max_test_acc_avg: 0.7831765935214211, max_test_f1_avg: 0.7460047890962085

count:86_repeat:0_time:2021-07-16 10:02:02
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6bd63ac6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 86 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 0 max_test_acc: 0.7821316614420063, max_test_f1: 0.7429478561157802
count:86_repeat:1_time:2021-07-16 10:05:37
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6bd63ac6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 86 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 1 max_test_acc: 0.7789968652037618, max_test_f1: 0.7469753340969837
count:86_repeat:2_time:2021-07-16 10:08:38
 model_name: EnsembleDB dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x7f6bd63ac6a8> learning_rate: 2e-05 l2reg: 0.001 num_epoch: 100 batch_size: 20 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.3 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 9 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 9 edge_type_number: 2 count: 86 dependency_type: stanza_spacy redroop_alpha: 0.5 model_class: <class 'models.ensemble_DB_Bert.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] syntactic_parsing: ['stanza', 'spacy'] repeat: 2 max_test_acc: 0.780564263322884, max_test_f1: 0.7357591539448257
max_test_acc_avg: 0.780564263322884, max_test_f1_avg: 0.7418941147191965

