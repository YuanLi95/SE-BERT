count:0_repeat:0_time:2021-06-27 15:44:20
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002050940B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:47:57
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001F389A3B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:48:29
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002298D30B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:49:31
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001770B5DB950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:51:21
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000019B0B58B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:52:06
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000020C0B1DB950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:53:40
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002E00A40B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:54:13
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001DF8468B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:55:22
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000021E09A7B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:55:53
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001B30BB0B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:58:51
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000027B8C05B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:59:31
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002930AD8B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 15:59:53
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001A50B83B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:00:51
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001AE9009B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 DT_layer_number: 6 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:13:25
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002A98CB4B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:14:08
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002420E08B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:14:38
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001A70E49B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:16:06
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002D509EFB950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:16:41
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001A70C83B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 0 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:17:10
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002578827B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:18:36
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002420A99B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:19:28
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000023B8D16B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:21:38
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000023F8F98B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:24:30
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001EF0A74B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:26:09
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002678E2AB950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:27:12
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000002348BB7B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:29:26
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000023F0AD1B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:30:07
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000012A0CB7B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:32:22
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x000001C88FE9B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 count:0_repeat:0_time:2021-06-27 16:33:33
 model_name: De_Bert_Muti dataset: lap14 optimizer: <class 'torch.optim.adam.Adam'> initializer: <function xavier_uniform_ at 0x0000029B0E20B950> learning_rate: 5e-06 l2reg: 0.0001 num_epoch: 100 batch_size: 6 log_step: 5 embed_dim: 300 position_dim: 768 position_drop: 0.4 dependency_edge_dim: 100 pretrained_weights: bert-base-uncased num_labels: 3 K_alpha: 1.0 V_alpha: 0.0 n_gpu: 1 hidden_dim: 300 polarities_dim: 3 save: True seed: 3 device: cuda:0 use_lstm_attention: True use_bert: False use_speech_weight: True lcf: cdw num_hidden_layers: 12 SRD: 3 lr_de: 0.5 DB_begin_layer: 8 count: 0 model_class: <class 'models.dependecy_bert_mutilayer.BertForSequenceClassification'> inputs_cols: ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph_undir', 'dependency_edge_matrix_undir', 'position_syntax_indices', 'aspect_double_idx', 'attention_mask'] repeat: 0 